

==== Training started at 2025-07-08 00:07:23.307025 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.7226 | Train Acc: 37.63%
Val Loss: 0.6934 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 64
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 2/50
Train Loss: 0.7141 | Train Acc: 43.01%
Val Loss: 0.6931 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 3/50
Train Loss: 0.6999 | Train Acc: 54.84%
Val Loss: 0.6919 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 56
Label distribution in training epoch: Counter({0: 55, 1: 38})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 4/50
Train Loss: 0.7023 | Train Acc: 50.54%
Val Loss: 0.6855 | Val Acc: 68.75%
Precision: 0.3438 | Recall: 0.5000 | F1 Score: 0.4074
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 64
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 5/50
Train Loss: 0.7100 | Train Acc: 47.31%
Val Loss: 0.6914 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 61
Label distribution in training epoch: Counter({1: 55, 0: 38})

Validation loss did not improve. Patience: 1/15

Epoch 6/50
Train Loss: 0.6946 | Train Acc: 51.61%
Val Loss: 0.6893 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 56
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 2/15

Epoch 7/50
Train Loss: 0.6784 | Train Acc: 56.99%
Val Loss: 0.6802 | Val Acc: 68.75%
Precision: 0.3438 | Recall: 0.5000 | F1 Score: 0.4074
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 55
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 8/50
Train Loss: 0.7006 | Train Acc: 52.69%
Val Loss: 0.6932 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 54
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 1/15

Epoch 9/50
Train Loss: 0.7050 | Train Acc: 51.61%
Val Loss: 0.7002 | Val Acc: 34.38%
Precision: 0.1774 | Recall: 0.4583 | F1 Score: 0.2558
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 57
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 2/15

Epoch 10/50
Train Loss: 0.7019 | Train Acc: 49.46%
Val Loss: 0.7264 | Val Acc: 43.75%
Precision: 0.3314 | Recall: 0.3806 | F1 Score: 0.3455
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 3/15

Epoch 11/50
Train Loss: 0.7080 | Train Acc: 45.16%
Val Loss: 0.6874 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 64
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 4/15

Epoch 12/50
Train Loss: 0.6994 | Train Acc: 53.76%
Val Loss: 1.0348 | Val Acc: 62.50%
Precision: 0.6235 | Recall: 0.6196 | F1 Score: 0.6190
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 62
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 5/15

Epoch 13/50
Train Loss: 0.7228 | Train Acc: 38.71%
Val Loss: 0.6746 | Val Acc: 46.88%
Precision: 0.3593 | Recall: 0.4246 | F1 Score: 0.3637
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 57
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 14/50
Train Loss: 0.7249 | Train Acc: 34.41%
Val Loss: 0.7263 | Val Acc: 56.25%
Precision: 0.6250 | Recall: 0.5952 | F1 Score: 0.5466
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 55
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 1/15

Epoch 15/50
Train Loss: 0.7062 | Train Acc: 45.16%
Val Loss: 0.9261 | Val Acc: 40.62%
Precision: 0.3141 | Recall: 0.3863 | F1 Score: 0.3267
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 2/15

Epoch 16/50
Train Loss: 0.6828 | Train Acc: 52.69%
Val Loss: 0.8176 | Val Acc: 75.00%
Precision: 0.7246 | Recall: 0.7013 | F1 Score: 0.7091
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 63
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 3/15

Epoch 17/50
Train Loss: 0.6938 | Train Acc: 52.69%
Val Loss: 0.6915 | Val Acc: 53.12%
Precision: 0.5312 | Recall: 0.5314 | F1 Score: 0.5308
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 58
Label distribution in training epoch: Counter({1: 55, 0: 38})

Validation loss did not improve. Patience: 4/15

Epoch 18/50
Train Loss: 0.7053 | Train Acc: 48.39%
Val Loss: 0.8401 | Val Acc: 40.62%
Precision: 0.4792 | Recall: 0.4827 | F1 Score: 0.4010
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 56
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 5/15

Epoch 19/50
Train Loss: 0.7145 | Train Acc: 46.24%
Val Loss: 0.9296 | Val Acc: 43.75%
Precision: 0.4058 | Recall: 0.4235 | F1 Score: 0.4000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 61
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 6/15

Epoch 20/50
Train Loss: 0.7045 | Train Acc: 46.24%
Val Loss: 0.8186 | Val Acc: 37.50%
Precision: 0.3810 | Recall: 0.3810 | F1 Score: 0.3750
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 56
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 7/15

Epoch 21/50
Train Loss: 0.7141 | Train Acc: 48.39%
Val Loss: 0.6740 | Val Acc: 59.38%
Precision: 0.5963 | Recall: 0.5516 | F1 Score: 0.5135
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 59
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 22/50
Train Loss: 0.7028 | Train Acc: 50.54%
Val Loss: 0.9408 | Val Acc: 65.62%
Precision: 0.5519 | Recall: 0.5318 | F1 Score: 0.5211
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 1/15

Epoch 23/50
Train Loss: 0.6969 | Train Acc: 53.76%
Val Loss: 1.1372 | Val Acc: 43.75%
Precision: 0.4413 | Recall: 0.4431 | F1 Score: 0.4353
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 2/15

Epoch 24/50
Train Loss: 0.7069 | Train Acc: 49.46%
Val Loss: 0.6354 | Val Acc: 78.12%
Precision: 0.8136 | Recall: 0.7706 | F1 Score: 0.7703
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 57
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 25/50
Train Loss: 0.6897 | Train Acc: 51.61%
Val Loss: 0.6817 | Val Acc: 71.88%
Precision: 0.7389 | Recall: 0.7341 | F1 Score: 0.7185
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 60
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 1/15

Epoch 26/50
Train Loss: 0.6813 | Train Acc: 51.61%
Val Loss: 0.6734 | Val Acc: 62.50%
Precision: 0.3125 | Recall: 0.5000 | F1 Score: 0.3846
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 2/15

Epoch 27/50
Train Loss: 0.6797 | Train Acc: 58.06%
Val Loss: 0.8508 | Val Acc: 56.25%
Precision: 0.5667 | Recall: 0.5625 | F1 Score: 0.5556
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 54
Label distribution in training epoch: Counter({1: 57, 0: 36})

Validation loss did not improve. Patience: 3/15

Epoch 28/50
Train Loss: 0.7007 | Train Acc: 45.16%
Val Loss: 0.8618 | Val Acc: 62.50%
Precision: 0.5417 | Recall: 0.5364 | F1 Score: 0.5362
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 4/15

Epoch 29/50
Train Loss: 0.6931 | Train Acc: 54.84%
Val Loss: 0.9118 | Val Acc: 59.38%
Precision: 0.5955 | Recall: 0.5824 | F1 Score: 0.5733
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 29: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 5/15

Epoch 30/50
Train Loss: 0.7184 | Train Acc: 46.24%
Val Loss: 0.7003 | Val Acc: 50.00%
Precision: 0.5000 | Recall: 0.5000 | F1 Score: 0.3816
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 30: 54
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 6/15

Epoch 31/50
Train Loss: 0.6896 | Train Acc: 54.84%
Val Loss: 1.3913 | Val Acc: 40.62%
Precision: 0.3542 | Recall: 0.3902 | F1 Score: 0.3552
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 31: 57
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 7/15

Epoch 32/50
Train Loss: 0.6845 | Train Acc: 60.22%
Val Loss: 0.9903 | Val Acc: 56.25%
Precision: 0.6073 | Recall: 0.6280 | F1 Score: 0.5556
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 32: 62
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 8/15

Epoch 33/50
Train Loss: 0.6978 | Train Acc: 51.61%
Val Loss: 0.8221 | Val Acc: 43.75%
Precision: 0.3720 | Recall: 0.3927 | F1 Score: 0.3766
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 33: 58
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 9/15

Epoch 34/50
Train Loss: 0.6912 | Train Acc: 55.91%
Val Loss: 0.6762 | Val Acc: 68.75%
Precision: 0.8000 | Recall: 0.7059 | F1 Score: 0.6667
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 34: 57
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 10/15

Epoch 35/50
Train Loss: 0.6872 | Train Acc: 60.22%
Val Loss: 0.7089 | Val Acc: 34.38%
Precision: 0.1719 | Recall: 0.5000 | F1 Score: 0.2558
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 35: 60
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 11/15

Epoch 36/50
Train Loss: 0.7046 | Train Acc: 45.16%
Val Loss: 0.7681 | Val Acc: 56.25%
Precision: 0.5417 | Recall: 0.5317 | F1 Score: 0.5152
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 36: 58
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 12/15

Epoch 37/50
Train Loss: 0.6945 | Train Acc: 55.91%
Val Loss: 0.7945 | Val Acc: 59.38%
Precision: 0.5972 | Recall: 0.5938 | F1 Score: 0.5901
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 37: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 13/15

Epoch 38/50
Train Loss: 0.7018 | Train Acc: 52.69%
Val Loss: 0.7222 | Val Acc: 40.62%
Precision: 0.3782 | Recall: 0.4255 | F1 Score: 0.3552
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 38: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 14/15

Epoch 39/50
Train Loss: 0.7061 | Train Acc: 49.46%
Val Loss: 0.7373 | Val Acc: 50.00%
Precision: 0.2759 | Recall: 0.4211 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 39: 54
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 15/15

Early stopping triggered after 39 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth for final metrics.
######## Training Finished in 0h 19m 9s ###########
Test Accuracy on 32 images: 46.88%
AUC: 0.5917
Class 0-non-cancer: Precision: 0.73, Recall: 0.80, F1-Score: 0.76
Class 1-cancer: Precision: 0.60, Recall: 0.50, F1-Score: 0.55
