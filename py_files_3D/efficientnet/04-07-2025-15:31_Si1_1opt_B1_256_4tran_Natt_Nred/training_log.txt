

==== Training started at 2025-07-04 15:31:57.712550 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.6933 | Train Acc: 50.54%
Val Loss: 0.6940 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 55
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.6955 | Train Acc: 48.39%
Val Loss: 0.6951 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 66
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 1/20

Epoch 3/50
Train Loss: 0.6904 | Train Acc: 52.69%
Val Loss: 0.6933 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 54
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 4/50
Train Loss: 0.6969 | Train Acc: 45.16%
Val Loss: 0.6899 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 5/50
Train Loss: 0.6970 | Train Acc: 49.46%
Val Loss: 0.6922 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 1/20

Epoch 6/50
Train Loss: 0.6968 | Train Acc: 45.16%
Val Loss: 0.6979 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 63
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 2/20

Epoch 7/50
Train Loss: 0.6931 | Train Acc: 47.31%
Val Loss: 0.6998 | Val Acc: 21.88%
Precision: 0.1094 | Recall: 0.5000 | F1 Score: 0.1795
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 64
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 3/20

Epoch 8/50
Train Loss: 0.6928 | Train Acc: 51.61%
Val Loss: 0.6941 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 57
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 4/20

Epoch 9/50
Train Loss: 0.6951 | Train Acc: 44.09%
Val Loss: 0.6930 | Val Acc: 53.12%
Precision: 0.2833 | Recall: 0.4474 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 64
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 5/20

Epoch 10/50
Train Loss: 0.6932 | Train Acc: 52.69%
Val Loss: 0.6974 | Val Acc: 37.50%
Precision: 0.2000 | Recall: 0.4286 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 56
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 6/20

Epoch 11/50
Train Loss: 0.6960 | Train Acc: 43.01%
Val Loss: 0.6972 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 52
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 7/20

Epoch 12/50
Train Loss: 0.6949 | Train Acc: 45.16%
Val Loss: 0.6900 | Val Acc: 62.50%
Precision: 0.3125 | Recall: 0.5000 | F1 Score: 0.3846
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 57
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 8/20

Epoch 13/50
Train Loss: 0.6890 | Train Acc: 54.84%
Val Loss: 0.6901 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 55
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 9/20

Epoch 14/50
Train Loss: 0.6915 | Train Acc: 58.06%
Val Loss: 0.6942 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 63
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 10/20

Epoch 15/50
Train Loss: 0.6911 | Train Acc: 54.84%
Val Loss: 0.6856 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 58
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 16/50
Train Loss: 0.6929 | Train Acc: 51.61%
Val Loss: 0.6916 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 61
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 1/20

Epoch 17/50
Train Loss: 0.6903 | Train Acc: 56.99%
Val Loss: 0.6874 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 55
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 2/20

Epoch 18/50
Train Loss: 0.6880 | Train Acc: 58.06%
Val Loss: 0.6922 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 57
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 3/20

Epoch 19/50
Train Loss: 0.6925 | Train Acc: 50.54%
Val Loss: 0.6979 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 56
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 4/20

Epoch 20/50
Train Loss: 0.6947 | Train Acc: 48.39%
Val Loss: 0.6939 | Val Acc: 40.62%
Precision: 0.2031 | Recall: 0.5000 | F1 Score: 0.2889
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 5/20

Epoch 21/50
Train Loss: 0.6807 | Train Acc: 64.52%
Val Loss: 0.6941 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 55
Label distribution in training epoch: Counter({0: 60, 1: 33})

Validation loss did not improve. Patience: 6/20

Epoch 22/50
Train Loss: 0.6900 | Train Acc: 51.61%
Val Loss: 0.6995 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 59
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 7/20

Epoch 23/50
Train Loss: 0.7007 | Train Acc: 40.86%
Val Loss: 0.6849 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 57
Label distribution in training epoch: Counter({1: 56, 0: 37})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 24/50
Train Loss: 0.6925 | Train Acc: 53.76%
Val Loss: 0.6946 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 61
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 1/20

Epoch 25/50
Train Loss: 0.6866 | Train Acc: 61.29%
Val Loss: 0.6935 | Val Acc: 56.25%
Precision: 0.6092 | Recall: 0.5373 | F1 Score: 0.4589
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 59
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 2/20

Epoch 26/50
Train Loss: 0.6895 | Train Acc: 59.14%
Val Loss: 0.6926 | Val Acc: 62.50%
Precision: 0.8065 | Recall: 0.5385 | F1 Score: 0.4514
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 57
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 3/20

Epoch 27/50
Train Loss: 0.6888 | Train Acc: 51.61%
Val Loss: 0.6972 | Val Acc: 40.62%
Precision: 0.2031 | Recall: 0.5000 | F1 Score: 0.2889
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 56
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 4/20

Epoch 28/50
Train Loss: 0.6948 | Train Acc: 52.69%
Val Loss: 0.6974 | Val Acc: 43.75%
Precision: 0.4222 | Recall: 0.4588 | F1 Score: 0.3766
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 58
Label distribution in training epoch: Counter({1: 55, 0: 38})

Validation loss did not improve. Patience: 5/20

Epoch 29/50
Train Loss: 0.6871 | Train Acc: 65.59%
Val Loss: 0.7067 | Val Acc: 40.62%
Precision: 0.4045 | Recall: 0.4176 | F1 Score: 0.3914
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 29: 61
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 6/20

Epoch 30/50
Train Loss: 0.6886 | Train Acc: 53.76%
Val Loss: 0.6908 | Val Acc: 59.38%
Precision: 0.7759 | Recall: 0.5938 | F1 Score: 0.5135
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 30: 54
Label distribution in training epoch: Counter({0: 55, 1: 38})

Validation loss did not improve. Patience: 7/20

Epoch 31/50
Train Loss: 0.6944 | Train Acc: 51.61%
Val Loss: 0.6953 | Val Acc: 40.62%
Precision: 0.6833 | Recall: 0.5476 | F1 Score: 0.3552
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 31: 60
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 8/20

Epoch 32/50
Train Loss: 0.6822 | Train Acc: 66.67%
Val Loss: 0.6882 | Val Acc: 62.50%
Precision: 0.3125 | Recall: 0.5000 | F1 Score: 0.3846
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 32: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 9/20

Epoch 33/50
Train Loss: 0.6885 | Train Acc: 56.99%
Val Loss: 0.7074 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 33: 59
Label distribution in training epoch: Counter({0: 56, 1: 37})

Validation loss did not improve. Patience: 10/20

Epoch 34/50
Train Loss: 0.6919 | Train Acc: 52.69%
Val Loss: 0.6878 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 34: 52
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 11/20

Epoch 35/50
Train Loss: 0.6974 | Train Acc: 48.39%
Val Loss: 0.6941 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 35: 59
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 12/20

Epoch 36/50
Train Loss: 0.6896 | Train Acc: 50.54%
Val Loss: 0.6910 | Val Acc: 59.38%
Precision: 0.5500 | Recall: 0.5121 | F1 Score: 0.4340
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 36: 59
Label distribution in training epoch: Counter({1: 56, 0: 37})

Validation loss did not improve. Patience: 13/20

Epoch 37/50
Train Loss: 0.6855 | Train Acc: 65.59%
Val Loss: 0.6955 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 37: 58
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 14/20

Epoch 38/50
Train Loss: 0.6911 | Train Acc: 47.31%
Val Loss: 0.6944 | Val Acc: 40.62%
Precision: 0.5171 | Recall: 0.5136 | F1 Score: 0.4010
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 38: 59
Label distribution in training epoch: Counter({1: 57, 0: 36})

Validation loss did not improve. Patience: 15/20

Epoch 39/50
Train Loss: 0.6886 | Train Acc: 56.99%
Val Loss: 0.6954 | Val Acc: 53.12%
Precision: 0.6407 | Recall: 0.5754 | F1 Score: 0.4910
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 39: 54
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 16/20

Epoch 40/50
Train Loss: 0.6897 | Train Acc: 61.29%
Val Loss: 0.6961 | Val Acc: 46.88%
Precision: 0.4500 | Recall: 0.4569 | F1 Score: 0.4421
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 40: 54
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 17/20

Epoch 41/50
Train Loss: 0.6896 | Train Acc: 55.91%
Val Loss: 0.6934 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 41: 56
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 18/20

Epoch 42/50
Train Loss: 0.6889 | Train Acc: 51.61%
Val Loss: 0.6940 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 42: 54
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 19/20

Epoch 43/50
Train Loss: 0.6884 | Train Acc: 55.91%
Val Loss: 0.6973 | Val Acc: 40.62%
Precision: 0.2031 | Recall: 0.5000 | F1 Score: 0.2889
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 43: 58
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 20/20

Early stopping triggered after 43 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 0h 17m 14s ###########
Test Accuracy on 32 images: 50.00%
AUC: 0.2105
Class 0-non-cancer: Precision: 0.56, Recall: 1.00, F1-Score: 0.72
Class 1-cancer: Precision: 0.00, Recall: 0.00, F1-Score: 0.00
