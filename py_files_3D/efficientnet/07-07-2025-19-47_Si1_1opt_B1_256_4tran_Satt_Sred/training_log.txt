

==== Training started at 2025-07-07 19:47:42.336068 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.6942 | Train Acc: 48.39%
Val Loss: 0.6922 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 55
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.6920 | Train Acc: 48.39%
Val Loss: 0.6921 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 58
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 3/50
Train Loss: 0.7079 | Train Acc: 38.71%
Val Loss: 0.6936 | Val Acc: 34.38%
Precision: 0.1719 | Recall: 0.5000 | F1 Score: 0.2558
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 62
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 1/15

Epoch 4/50
Train Loss: 0.6957 | Train Acc: 46.24%
Val Loss: 0.6933 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 65
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 2/15

Epoch 5/50
Train Loss: 0.6953 | Train Acc: 46.24%
Val Loss: 0.6914 | Val Acc: 65.62%
Precision: 0.3281 | Recall: 0.5000 | F1 Score: 0.3962
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 55
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 6/50
Train Loss: 0.6956 | Train Acc: 50.54%
Val Loss: 0.6905 | Val Acc: 68.75%
Precision: 0.3438 | Recall: 0.5000 | F1 Score: 0.4074
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 53
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 7/50
Train Loss: 0.6923 | Train Acc: 53.76%
Val Loss: 0.6885 | Val Acc: 65.62%
Precision: 0.3281 | Recall: 0.5000 | F1 Score: 0.3962
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 54
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 8/50
Train Loss: 0.6982 | Train Acc: 49.46%
Val Loss: 0.6887 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 58
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 1/15

Epoch 9/50
Train Loss: 0.6950 | Train Acc: 48.39%
Val Loss: 0.6943 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 58
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 2/15

Epoch 10/50
Train Loss: 0.6713 | Train Acc: 63.44%
Val Loss: 0.7348 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 58
Label distribution in training epoch: Counter({1: 59, 0: 34})

Validation loss did not improve. Patience: 3/15

Epoch 11/50
Train Loss: 0.6884 | Train Acc: 54.84%
Val Loss: 0.7342 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 60
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 4/15

Epoch 12/50
Train Loss: 0.7014 | Train Acc: 49.46%
Val Loss: 0.7606 | Val Acc: 50.00%
Precision: 0.4841 | Recall: 0.4833 | F1 Score: 0.4818
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 63
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 5/15

Epoch 13/50
Train Loss: 0.6934 | Train Acc: 49.46%
Val Loss: 0.6898 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 57
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 6/15

Epoch 14/50
Train Loss: 0.6939 | Train Acc: 47.31%
Val Loss: 0.6909 | Val Acc: 53.12%
Precision: 0.5081 | Recall: 0.5083 | F1 Score: 0.5077
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 63
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 7/15

Epoch 15/50
Train Loss: 0.6917 | Train Acc: 51.61%
Val Loss: 0.7624 | Val Acc: 68.75%
Precision: 0.6970 | Recall: 0.6784 | F1 Score: 0.6761
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 8/15

Epoch 16/50
Train Loss: 0.6964 | Train Acc: 50.54%
Val Loss: 0.8133 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 59
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 9/15

Epoch 17/50
Train Loss: 0.6896 | Train Acc: 56.99%
Val Loss: 0.8884 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 61
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 10/15

Epoch 18/50
Train Loss: 0.7081 | Train Acc: 45.16%
Val Loss: 0.7041 | Val Acc: 78.12%
Precision: 0.7902 | Recall: 0.8083 | F1 Score: 0.7793
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 62
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 11/15

Epoch 19/50
Train Loss: 0.6982 | Train Acc: 46.24%
Val Loss: 0.7440 | Val Acc: 59.38%
Precision: 0.5583 | Recall: 0.5606 | F1 Score: 0.5589
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 12/15

Epoch 20/50
Train Loss: 0.6938 | Train Acc: 51.61%
Val Loss: 0.6938 | Val Acc: 68.75%
Precision: 0.7150 | Recall: 0.6745 | F1 Score: 0.6667
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 58
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 13/15

Epoch 21/50
Train Loss: 0.6999 | Train Acc: 49.46%
Val Loss: 0.9185 | Val Acc: 68.75%
Precision: 0.6761 | Recall: 0.6761 | F1 Score: 0.6761
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 57
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 14/15

Epoch 22/50
Train Loss: 0.6938 | Train Acc: 50.54%
Val Loss: 0.6783 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 58
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 23/50
Train Loss: 0.6945 | Train Acc: 52.69%
Val Loss: 0.7558 | Val Acc: 50.00%
Precision: 0.4727 | Recall: 0.4762 | F1 Score: 0.4667
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 54
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 1/15

Epoch 24/50
Train Loss: 0.7008 | Train Acc: 50.54%
Val Loss: 0.8920 | Val Acc: 46.88%
Precision: 0.4654 | Recall: 0.4688 | F1 Score: 0.4555
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 56
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 2/15

Epoch 25/50
Train Loss: 0.6959 | Train Acc: 48.39%
Val Loss: 0.6820 | Val Acc: 59.38%
Precision: 0.6875 | Recall: 0.6457 | F1 Score: 0.5836
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 3/15

Epoch 26/50
Train Loss: 0.7031 | Train Acc: 41.94%
Val Loss: 0.6815 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 65
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 4/15

Epoch 27/50
Train Loss: 0.6945 | Train Acc: 52.69%
Val Loss: 0.6730 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 56
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 28/50
Train Loss: 0.6958 | Train Acc: 50.54%
Val Loss: 0.6157 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 54
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 29/50
Train Loss: 0.6866 | Train Acc: 54.84%
Val Loss: 0.6897 | Val Acc: 50.00%
Precision: 0.4593 | Recall: 0.4784 | F1 Score: 0.4182
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 29: 59
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 1/15

Epoch 30/50
Train Loss: 0.6992 | Train Acc: 47.31%
Val Loss: 0.7045 | Val Acc: 50.00%
Precision: 0.2759 | Recall: 0.4211 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 30: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 2/15

Epoch 31/50
Train Loss: 0.6844 | Train Acc: 52.69%
Val Loss: 0.8049 | Val Acc: 53.12%
Precision: 0.4425 | Recall: 0.4802 | F1 Score: 0.3992
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 31: 61
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 3/15

Epoch 32/50
Train Loss: 0.6962 | Train Acc: 46.24%
Val Loss: 1.6286 | Val Acc: 53.12%
Precision: 0.5324 | Recall: 0.5312 | F1 Score: 0.5271
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 32: 55
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 4/15

Epoch 33/50
Train Loss: 0.6981 | Train Acc: 51.61%
Val Loss: 0.7966 | Val Acc: 37.50%
Precision: 0.4000 | Recall: 0.4000 | F1 Score: 0.3750
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 33: 63
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 5/15

Epoch 34/50
Train Loss: 0.6977 | Train Acc: 45.16%
Val Loss: 0.7674 | Val Acc: 65.62%
Precision: 0.6682 | Recall: 0.6451 | F1 Score: 0.6390
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 34: 56
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 6/15

Epoch 35/50
Train Loss: 0.6959 | Train Acc: 45.16%
Val Loss: 0.8584 | Val Acc: 40.62%
Precision: 0.3502 | Recall: 0.3770 | F1 Score: 0.3552
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 35: 58
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 7/15

Epoch 36/50
Train Loss: 0.6974 | Train Acc: 51.61%
Val Loss: 0.7201 | Val Acc: 40.62%
Precision: 0.4143 | Recall: 0.4405 | F1 Score: 0.3764
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 36: 63
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 8/15

Epoch 37/50
Train Loss: 0.6881 | Train Acc: 58.06%
Val Loss: 0.6641 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 37: 56
Label distribution in training epoch: Counter({0: 59, 1: 34})

Validation loss did not improve. Patience: 9/15

Epoch 38/50
Train Loss: 0.7036 | Train Acc: 44.09%
Val Loss: 0.6813 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 38: 61
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 10/15

Epoch 39/50
Train Loss: 0.6928 | Train Acc: 46.24%
Val Loss: 0.7608 | Val Acc: 40.62%
Precision: 0.3227 | Recall: 0.3312 | F1 Score: 0.3267
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 39: 55
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 11/15

Epoch 40/50
Train Loss: 0.6893 | Train Acc: 52.69%
Val Loss: 0.6867 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 40: 55
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 12/15

Epoch 41/50
Train Loss: 0.6956 | Train Acc: 50.54%
Val Loss: 0.7208 | Val Acc: 40.62%
Precision: 0.4375 | Recall: 0.4514 | F1 Score: 0.3914
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 41: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 13/15

Epoch 42/50
Train Loss: 0.6863 | Train Acc: 50.54%
Val Loss: 0.6415 | Val Acc: 65.62%
Precision: 0.3281 | Recall: 0.5000 | F1 Score: 0.3962
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 42: 59
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 14/15

Epoch 43/50
Train Loss: 0.6977 | Train Acc: 47.31%
Val Loss: 1.0948 | Val Acc: 37.50%
Precision: 0.3506 | Recall: 0.3647 | F1 Score: 0.3522
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 43: 57
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 15/15

Early stopping triggered after 43 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 0h 21m 32s ###########
Test Accuracy on 32 images: 50.00%
AUC: 0.3020
Class 0-non-cancer: Precision: 0.53, Recall: 1.00, F1-Score: 0.69
Class 1-cancer: Precision: 0.00, Recall: 0.00, F1-Score: 0.00
