

==== Training started at 2025-07-10 04:17:28.792425 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 4
Effective batch size: 16

Epoch 1/50
Train Loss: 0.6828 | Train Acc: 55.93%
Val Loss: 0.7715 | Val Acc: 44.64%
Precision: 0.4217 | Recall: 0.4488 | F1 Score: 0.3955
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 1: 93
Label distribution in training epoch: Counter({0: 2826, 1: 2754})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 2/50
Train Loss: 0.4925 | Train Acc: 75.81%
Val Loss: 0.8109 | Val Acc: 57.71%
Precision: 0.6126 | Recall: 0.5622 | F1 Score: 0.5152
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({1: 2855, 0: 2725})

Validation loss did not improve. Patience: 1/15

Epoch 3/50
Train Loss: 0.3165 | Train Acc: 87.71%
Val Loss: 1.3185 | Val Acc: 46.67%
Precision: 0.4506 | Recall: 0.4722 | F1 Score: 0.4050
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({0: 2817, 1: 2763})

Validation loss did not improve. Patience: 2/15

Epoch 4/50
Train Loss: 0.2586 | Train Acc: 90.22%
Val Loss: 1.1526 | Val Acc: 59.95%
Precision: 0.6558 | Recall: 0.6049 | F1 Score: 0.5663
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({1: 2833, 0: 2747})

Validation loss did not improve. Patience: 3/15

Epoch 5/50
Train Loss: 0.2226 | Train Acc: 91.65%
Val Loss: 1.5224 | Val Acc: 53.85%
Precision: 0.5591 | Recall: 0.5456 | F1 Score: 0.5139
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({0: 2791, 1: 2789})

Validation loss did not improve. Patience: 4/15

Epoch 6/50
Train Loss: 0.2000 | Train Acc: 92.24%
Val Loss: 1.7602 | Val Acc: 54.79%
Precision: 0.5623 | Recall: 0.5477 | F1 Score: 0.5196
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({1: 2793, 0: 2787})

Validation loss did not improve. Patience: 5/15

Epoch 7/50
Train Loss: 0.1858 | Train Acc: 93.06%
Val Loss: 1.5075 | Val Acc: 62.14%
Precision: 0.6414 | Recall: 0.6246 | F1 Score: 0.6110
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({1: 2812, 0: 2768})

Validation loss did not improve. Patience: 6/15

Epoch 8/50
Train Loss: 0.1816 | Train Acc: 92.97%
Val Loss: 1.8300 | Val Acc: 60.89%
Precision: 0.6649 | Recall: 0.6070 | F1 Score: 0.5703
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({1: 2799, 0: 2781})

Validation loss did not improve. Patience: 7/15

Epoch 9/50
Train Loss: 0.1568 | Train Acc: 93.24%
Val Loss: 2.0854 | Val Acc: 59.90%
Precision: 0.6365 | Recall: 0.6069 | F1 Score: 0.5792
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({0: 2839, 1: 2741})

Validation loss did not improve. Patience: 8/15

Epoch 10/50
Train Loss: 0.1576 | Train Acc: 93.24%
Val Loss: 1.4596 | Val Acc: 53.39%
Precision: 0.5387 | Recall: 0.5314 | F1 Score: 0.5094
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({0: 2840, 1: 2740})

Validation loss did not improve. Patience: 9/15

Epoch 11/50
Train Loss: 0.1241 | Train Acc: 94.43%
Val Loss: 2.0513 | Val Acc: 59.58%
Precision: 0.6850 | Recall: 0.5903 | F1 Score: 0.5335
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({0: 2850, 1: 2730})

Validation loss did not improve. Patience: 10/15

Epoch 12/50
Train Loss: 0.1344 | Train Acc: 94.41%
Val Loss: 1.7393 | Val Acc: 55.73%
Precision: 0.5693 | Recall: 0.5605 | F1 Score: 0.5441
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({1: 2793, 0: 2787})

Validation loss did not improve. Patience: 11/15

Epoch 13/50
Train Loss: 0.1441 | Train Acc: 93.15%
Val Loss: 1.8833 | Val Acc: 47.71%
Precision: 0.4754 | Recall: 0.4791 | F1 Score: 0.4576
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({0: 2796, 1: 2784})

Validation loss did not improve. Patience: 12/15

Epoch 14/50
Train Loss: 0.1194 | Train Acc: 94.16%
Val Loss: 2.2367 | Val Acc: 57.14%
Precision: 0.5985 | Recall: 0.5676 | F1 Score: 0.5329
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({0: 2823, 1: 2757})

Validation loss did not improve. Patience: 13/15

Epoch 15/50
Train Loss: 0.1253 | Train Acc: 93.53%
Val Loss: 2.1045 | Val Acc: 51.67%
Precision: 0.5537 | Recall: 0.5318 | F1 Score: 0.4700
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 15: 93
Label distribution in training epoch: Counter({1: 2837, 0: 2743})

Validation loss did not improve. Patience: 14/15

Epoch 16/50
Train Loss: 0.1223 | Train Acc: 92.74%
Val Loss: 1.6612 | Val Acc: 52.60%
Precision: 0.5295 | Recall: 0.5274 | F1 Score: 0.5181
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 16: 93
Label distribution in training epoch: Counter({1: 2804, 0: 2776})

Validation loss did not improve. Patience: 15/15

Early stopping triggered after 16 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth for final metrics.
######## Training Finished in 7h 29m 56s ###########
Test Accuracy on 1920 images: 47.50%
AUC: 0.5388
Class 0-non-cancer: Precision: 0.38, Recall: 0.15, F1-Score: 0.21
Class 1-cancer: Precision: 0.46, Recall: 0.75, F1-Score: 0.57
