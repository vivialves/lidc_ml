

==== Training started at 2025-07-04 17:24:57.647976 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.6898 | Train Acc: 53.61%
Val Loss: 2.2521 | Val Acc: 53.97%
Precision: 0.5464 | Recall: 0.5422 | F1 Score: 0.5301
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 93
Label distribution in training epoch: Counter({1: 4667, 0: 4633})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.4144 | Train Acc: 87.85%
Val Loss: 6.4752 | Val Acc: 59.56%
Precision: 0.6086 | Recall: 0.5927 | F1 Score: 0.5789
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({1: 4745, 0: 4555})

Validation loss did not improve. Patience: 1/20

Epoch 3/50
Train Loss: 0.0133 | Train Acc: 99.76%
Val Loss: 10.5727 | Val Acc: 48.72%
Precision: 0.2436 | Recall: 0.5000 | F1 Score: 0.3276
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({1: 4703, 0: 4597})

Validation loss did not improve. Patience: 2/20

Epoch 4/50
Train Loss: 0.0050 | Train Acc: 99.92%
Val Loss: 6.8746 | Val Acc: 47.22%
Precision: 0.2427 | Recall: 0.4728 | F1 Score: 0.3207
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({0: 4653, 1: 4647})

Validation loss did not improve. Patience: 3/20

Epoch 5/50
Train Loss: 0.0036 | Train Acc: 99.95%
Val Loss: 7.0521 | Val Acc: 42.50%
Precision: 0.2234 | Recall: 0.4485 | F1 Score: 0.2982
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({0: 4706, 1: 4594})

Validation loss did not improve. Patience: 4/20

Epoch 6/50
Train Loss: 0.0019 | Train Acc: 99.97%
Val Loss: 10.7617 | Val Acc: 48.62%
Precision: 0.4577 | Recall: 0.4868 | F1 Score: 0.3801
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({0: 4650, 1: 4650})

Validation loss did not improve. Patience: 5/20

Epoch 7/50
Train Loss: 0.0020 | Train Acc: 99.96%
Val Loss: 6.8939 | Val Acc: 45.94%
Precision: 0.2437 | Recall: 0.4444 | F1 Score: 0.3148
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({1: 4659, 0: 4641})

Validation loss did not improve. Patience: 6/20

Epoch 8/50
Train Loss: 0.0009 | Train Acc: 99.98%
Val Loss: 7.1746 | Val Acc: 49.22%
Precision: 0.4933 | Recall: 0.4965 | F1 Score: 0.4251
Current AMP scale: 128.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({0: 4655, 1: 4645})

Validation loss did not improve. Patience: 7/20

Epoch 9/50
Train Loss: 0.0024 | Train Acc: 99.97%
Val Loss: 8.2629 | Val Acc: 41.72%
Precision: 0.3742 | Recall: 0.4403 | F1 Score: 0.3455
Current AMP scale: 128.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({1: 4742, 0: 4558})

Validation loss did not improve. Patience: 8/20

Epoch 10/50
Train Loss: 0.0017 | Train Acc: 99.97%
Val Loss: 8.1547 | Val Acc: 49.53%
Precision: 0.2477 | Recall: 0.5000 | F1 Score: 0.3312
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({0: 4684, 1: 4616})

Validation loss did not improve. Patience: 9/20

Epoch 11/50
Train Loss: 0.0011 | Train Acc: 99.97%
Val Loss: 10.0519 | Val Acc: 46.50%
Precision: 0.2397 | Recall: 0.4697 | F1 Score: 0.3174
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({1: 4727, 0: 4573})

Validation loss did not improve. Patience: 10/20

Epoch 12/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 7.3627 | Val Acc: 48.25%
Precision: 0.2412 | Recall: 0.5000 | F1 Score: 0.3255
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({0: 4653, 1: 4647})

Validation loss did not improve. Patience: 11/20

Epoch 13/50
Train Loss: 0.0023 | Train Acc: 99.97%
Val Loss: 14.8553 | Val Acc: 44.16%
Precision: 0.2346 | Recall: 0.4413 | F1 Score: 0.3063
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({0: 4651, 1: 4649})

Validation loss did not improve. Patience: 12/20

Epoch 14/50
Train Loss: 0.0004 | Train Acc: 99.99%
Val Loss: 19.7815 | Val Acc: 42.75%
Precision: 0.2313 | Recall: 0.4246 | F1 Score: 0.2995
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({0: 4683, 1: 4617})

Validation loss did not improve. Patience: 13/20

Epoch 15/50
Train Loss: 0.0005 | Train Acc: 99.99%
Val Loss: 12.3574 | Val Acc: 43.59%
Precision: 0.2293 | Recall: 0.4491 | F1 Score: 0.3036
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 15: 93
Label distribution in training epoch: Counter({1: 4659, 0: 4641})

Validation loss did not improve. Patience: 14/20

Epoch 16/50
Train Loss: 0.0033 | Train Acc: 99.95%
Val Loss: 11.0370 | Val Acc: 47.53%
Precision: 0.2422 | Recall: 0.4810 | F1 Score: 0.3222
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 16: 93
Label distribution in training epoch: Counter({0: 4683, 1: 4617})

Validation loss did not improve. Patience: 15/20

Epoch 17/50
Train Loss: 0.0003 | Train Acc: 99.99%
Val Loss: 13.0689 | Val Acc: 42.41%
Precision: 0.2236 | Recall: 0.4458 | F1 Score: 0.2978
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 17: 93
Label distribution in training epoch: Counter({1: 4732, 0: 4568})

Validation loss did not improve. Patience: 16/20

Epoch 18/50
Train Loss: 0.0014 | Train Acc: 99.97%
Val Loss: 14.4058 | Val Acc: 47.78%
Precision: 0.2470 | Recall: 0.4679 | F1 Score: 0.3233
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 18: 93
Label distribution in training epoch: Counter({1: 4679, 0: 4621})

Validation loss did not improve. Patience: 17/20

Epoch 19/50
Train Loss: 0.0016 | Train Acc: 99.98%
Val Loss: 14.2649 | Val Acc: 46.12%
Precision: 0.2367 | Recall: 0.4737 | F1 Score: 0.3157
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 19: 93
Label distribution in training epoch: Counter({1: 4693, 0: 4607})

Validation loss did not improve. Patience: 18/20

Epoch 20/50
Train Loss: 0.0011 | Train Acc: 99.99%
Val Loss: 13.9332 | Val Acc: 41.03%
Precision: 0.2215 | Recall: 0.4238 | F1 Score: 0.2909
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 20: 93
Label distribution in training epoch: Counter({0: 4675, 1: 4625})

Validation loss did not improve. Patience: 19/20

Epoch 21/50
Train Loss: 0.0009 | Train Acc: 99.99%
Val Loss: 18.0882 | Val Acc: 41.19%
Precision: 0.2234 | Recall: 0.4203 | F1 Score: 0.2917
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 21: 93
Label distribution in training epoch: Counter({1: 4657, 0: 4643})

Validation loss did not improve. Patience: 20/20

Early stopping triggered after 21 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 17h 33m 53s ###########
Test Accuracy on 3200 images: 45.25%
AUC: 0.5107
Class 0-non-cancer: Precision: 0.55, Recall: 0.38, F1-Score: 0.45
Class 1-cancer: Precision: 0.52, Recall: 0.69, F1-Score: 0.60
