

==== Training started at 2025-06-15 02:00:06.493170 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.1330 | Train Acc: 95.34%
Val Loss: 0.9997 | Val Acc: 45.10%
Precision: 0.3959 | Recall: 0.4417 | F1 Score: 0.3765
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 1: 93
Label distribution in training epoch: Counter({0: 2833, 1: 2747})

Validation loss improved. Saving best model to /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.0170 | Train Acc: 99.61%
Val Loss: 0.9846 | Val Acc: 55.89%
Precision: 0.5647 | Recall: 0.5537 | F1 Score: 0.5368
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({0: 2818, 1: 2762})

Validation loss improved. Saving best model to /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 3/50
Train Loss: 0.0044 | Train Acc: 99.98%
Val Loss: 1.5236 | Val Acc: 45.52%
Precision: 0.2369 | Recall: 0.4605 | F1 Score: 0.3128
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({1: 2795, 0: 2785})

Validation loss did not improve. Patience: 1/6

Epoch 4/50
Train Loss: 0.0069 | Train Acc: 99.86%
Val Loss: 1.1548 | Val Acc: 43.18%
Precision: 0.4302 | Recall: 0.4328 | F1 Score: 0.4271
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({1: 2815, 0: 2765})

Validation loss did not improve. Patience: 2/6

Epoch 5/50
Train Loss: 0.0048 | Train Acc: 99.91%
Val Loss: 1.2543 | Val Acc: 51.93%
Precision: 0.5252 | Recall: 0.5227 | F1 Score: 0.5087
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({1: 2835, 0: 2745})

Validation loss did not improve. Patience: 3/6

Epoch 6/50
Train Loss: 0.0068 | Train Acc: 99.78%
Val Loss: 1.0089 | Val Acc: 49.64%
Precision: 0.4985 | Recall: 0.4986 | F1 Score: 0.4892
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({1: 2888, 0: 2692})

Validation loss did not improve. Patience: 4/6

Epoch 7/50
Train Loss: 0.0014 | Train Acc: 99.98%
Val Loss: 1.2043 | Val Acc: 38.23%
Precision: 0.3796 | Recall: 0.3822 | F1 Score: 0.3789
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({0: 2828, 1: 2752})

Validation loss did not improve. Patience: 5/6

Epoch 8/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 0.9076 | Val Acc: 48.70%
Precision: 0.4121 | Recall: 0.4780 | F1 Score: 0.3616
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({0: 2837, 1: 2743})

Validation loss improved. Saving best model to /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 9/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 0.9671 | Val Acc: 48.12%
Precision: 0.4362 | Recall: 0.4683 | F1 Score: 0.3975
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({1: 2795, 0: 2785})

Validation loss did not improve. Patience: 1/6

Epoch 10/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 1.7976 | Val Acc: 53.44%
Precision: 0.7611 | Recall: 0.5260 | F1 Score: 0.3924
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({1: 2806, 0: 2774})

Validation loss did not improve. Patience: 2/6

Epoch 11/50
Train Loss: 0.0118 | Train Acc: 99.61%
Val Loss: 1.4837 | Val Acc: 45.68%
Precision: 0.3959 | Recall: 0.4605 | F1 Score: 0.3599
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({0: 2811, 1: 2769})

Validation loss did not improve. Patience: 3/6

Epoch 12/50
Train Loss: 0.0031 | Train Acc: 99.91%
Val Loss: 2.2289 | Val Acc: 46.30%
Precision: 0.4455 | Recall: 0.4576 | F1 Score: 0.4280
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({1: 2807, 0: 2773})

Validation loss did not improve. Patience: 4/6

Epoch 13/50
Train Loss: 0.0028 | Train Acc: 99.93%
Val Loss: 1.6015 | Val Acc: 48.12%
Precision: 0.4418 | Recall: 0.4739 | F1 Score: 0.3930
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({0: 2827, 1: 2753})

Validation loss did not improve. Patience: 5/6

Epoch 14/50
Train Loss: 0.0029 | Train Acc: 99.89%
Val Loss: 1.5466 | Val Acc: 45.42%
Precision: 0.4539 | Recall: 0.4575 | F1 Score: 0.4452
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({0: 2797, 1: 2783})

Validation loss did not improve. Patience: 6/6

Early stopping triggered after 14 epochs.


Training complete.
Loading best model from /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 3h 48m 36s ###########
Test Accuracy on 1920 images: 43.59%
AUC: 0.4644
Class 0-non-cancer: Precision: 0.49, Recall: 0.92, F1-Score: 0.64
Class 1-cancer: Precision: 0.42, Recall: 0.06, F1-Score: 0.10


==== Training started at 2025-06-15 09:20:12.567123 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.1211 | Train Acc: 96.08%
Val Loss: 53.0635 | Val Acc: 48.99%
Precision: 0.2450 | Recall: 0.5000 | F1 Score: 0.3288
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 1: 93
Label distribution in training epoch: Counter({1: 3082, 0: 2963})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.0140 | Train Acc: 99.74%
Val Loss: 3.6906 | Val Acc: 58.37%
Precision: 0.6216 | Recall: 0.5901 | F1 Score: 0.5577
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({0: 3048, 1: 2997})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 3/50
Train Loss: 0.0091 | Train Acc: 99.77%
Val Loss: 4.9309 | Val Acc: 59.18%
Precision: 0.6136 | Recall: 0.5953 | F1 Score: 0.5762
Current AMP scale: 128.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({0: 3094, 1: 2951})

Validation loss did not improve. Patience: 1/6

Epoch 4/50
Train Loss: 0.0046 | Train Acc: 99.92%
Val Loss: 4.5081 | Val Acc: 48.27%
Precision: 0.4815 | Recall: 0.4818 | F1 Score: 0.4801
Current AMP scale: 128.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({0: 3033, 1: 3012})

Validation loss did not improve. Patience: 2/6

Epoch 5/50
Train Loss: 0.0004 | Train Acc: 100.00%
Val Loss: 6.0081 | Val Acc: 53.70%
Precision: 0.5474 | Recall: 0.5361 | F1 Score: 0.5070
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({1: 3049, 0: 2996})

Validation loss did not improve. Patience: 3/6

Epoch 6/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 3.2601 | Val Acc: 48.56%
Precision: 0.4831 | Recall: 0.4840 | F1 Score: 0.4778
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({0: 3030, 1: 3015})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 7/50
Train Loss: 0.0037 | Train Acc: 99.88%
Val Loss: 5.6773 | Val Acc: 50.82%
Precision: 0.5165 | Recall: 0.5143 | F1 Score: 0.4936
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({1: 3031, 0: 3014})

Validation loss did not improve. Patience: 1/6

Epoch 8/50
Train Loss: 0.0035 | Train Acc: 99.97%
Val Loss: 5.8725 | Val Acc: 56.20%
Precision: 0.6208 | Recall: 0.5659 | F1 Score: 0.5080
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({1: 3069, 0: 2976})

Validation loss did not improve. Patience: 2/6

Epoch 9/50
Train Loss: 0.0008 | Train Acc: 99.97%
Val Loss: 9.0209 | Val Acc: 47.60%
Precision: 0.4379 | Recall: 0.4787 | F1 Score: 0.3750
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({1: 3073, 0: 2972})

Validation loss did not improve. Patience: 3/6

Epoch 10/50
Train Loss: 0.0091 | Train Acc: 99.74%
Val Loss: 0.7627 | Val Acc: 57.21%
Precision: 0.6081 | Recall: 0.5763 | F1 Score: 0.5402
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({0: 3037, 1: 3008})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 11/50
Train Loss: 0.0029 | Train Acc: 99.95%
Val Loss: 1.1929 | Val Acc: 56.59%
Precision: 0.5900 | Recall: 0.5624 | F1 Score: 0.5280
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({1: 3047, 0: 2998})

Validation loss did not improve. Patience: 1/6

Epoch 12/50
Train Loss: 0.0002 | Train Acc: 100.00%
Val Loss: 2.4235 | Val Acc: 57.74%
Precision: 0.6838 | Recall: 0.5886 | F1 Score: 0.5204
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({1: 3034, 0: 3011})

Validation loss did not improve. Patience: 2/6

Epoch 13/50
Train Loss: 0.0002 | Train Acc: 100.00%
Val Loss: 1.8216 | Val Acc: 64.47%
Precision: 0.6556 | Recall: 0.6464 | F1 Score: 0.6400
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({0: 3029, 1: 3016})

Validation loss did not improve. Patience: 3/6

Epoch 14/50
Train Loss: 0.0001 | Train Acc: 100.00%
Val Loss: 4.9879 | Val Acc: 57.69%
Precision: 0.5769 | Recall: 0.5769 | F1 Score: 0.5769
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({1: 3026, 0: 3019})

Validation loss did not improve. Patience: 4/6

Epoch 15/50
Train Loss: 0.0014 | Train Acc: 99.98%
Val Loss: 8.1417 | Val Acc: 31.63%
Precision: 0.2607 | Recall: 0.3239 | F1 Score: 0.2737
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 15: 93
Label distribution in training epoch: Counter({1: 3044, 0: 3001})

Validation loss did not improve. Patience: 5/6

Epoch 16/50
Train Loss: 0.0156 | Train Acc: 99.55%
Val Loss: 5.9097 | Val Acc: 42.93%
Precision: 0.4311 | Recall: 0.4324 | F1 Score: 0.4279
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 16: 93
Label distribution in training epoch: Counter({1: 3037, 0: 3008})

Validation loss did not improve. Patience: 6/6

Early stopping triggered after 16 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 6h 50m 34s ###########
Test Accuracy on 2080 images: 54.52%
AUC: 0.5873
Class 0-non-cancer: Precision: 0.74, Recall: 0.32, F1-Score: 0.44
Class 1-cancer: Precision: 0.56, Recall: 0.89, F1-Score: 0.69
