

==== Training started at 2025-07-06 07:42:45.757149 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.6940 | Train Acc: 50.91%
Val Loss: 2.1616 | Val Acc: 46.41%
Precision: 0.4622 | Recall: 0.4661 | F1 Score: 0.4509
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 93
Label distribution in training epoch: Counter({1: 957, 0: 903})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.6951 | Train Acc: 50.75%
Val Loss: 0.6440 | Val Acc: 49.53%
Precision: 0.4100 | Recall: 0.4814 | F1 Score: 0.3592
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({0: 936, 1: 924})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 3/50
Train Loss: 0.6930 | Train Acc: 51.88%
Val Loss: 1.2731 | Val Acc: 43.75%
Precision: 0.4292 | Recall: 0.4381 | F1 Score: 0.4197
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({1: 939, 0: 921})

Validation loss did not improve. Patience: 1/15

Epoch 4/50
Train Loss: 0.6888 | Train Acc: 53.60%
Val Loss: 2.5847 | Val Acc: 42.50%
Precision: 0.4228 | Recall: 0.4250 | F1 Score: 0.4209
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({0: 948, 1: 912})

Validation loss did not improve. Patience: 2/15

Epoch 5/50
Train Loss: 0.6864 | Train Acc: 55.59%
Val Loss: 3.3790 | Val Acc: 44.53%
Precision: 0.4489 | Recall: 0.4486 | F1 Score: 0.4451
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({1: 954, 0: 906})

Validation loss did not improve. Patience: 3/15

Epoch 6/50
Train Loss: 0.6735 | Train Acc: 59.35%
Val Loss: 0.8625 | Val Acc: 44.53%
Precision: 0.4403 | Recall: 0.4435 | F1 Score: 0.4367
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({1: 955, 0: 905})

Validation loss did not improve. Patience: 4/15

Epoch 7/50
Train Loss: 0.6280 | Train Acc: 75.97%
Val Loss: 1.4635 | Val Acc: 56.25%
Precision: 0.7694 | Recall: 0.5527 | F1 Score: 0.4455
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({1: 964, 0: 896})

Validation loss did not improve. Patience: 5/15

Epoch 8/50
Train Loss: 0.4921 | Train Acc: 95.48%
Val Loss: 18.2595 | Val Acc: 49.84%
Precision: 0.2492 | Recall: 0.5000 | F1 Score: 0.3326
Current AMP scale: 8192.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({1: 950, 0: 910})

Validation loss did not improve. Patience: 6/15

Epoch 9/50
Train Loss: 0.2724 | Train Acc: 99.30%
Val Loss: 10.8840 | Val Acc: 43.75%
Precision: 0.2369 | Recall: 0.4255 | F1 Score: 0.3043
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({1: 941, 0: 919})

Validation loss did not improve. Patience: 7/15

Epoch 10/50
Train Loss: 0.0851 | Train Acc: 99.25%
Val Loss: 8.1459 | Val Acc: 46.25%
Precision: 0.3820 | Recall: 0.4505 | F1 Score: 0.3620
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({1: 945, 0: 915})

Validation loss did not improve. Patience: 8/15

Epoch 11/50
Train Loss: 0.0294 | Train Acc: 99.52%
Val Loss: 13.4252 | Val Acc: 46.41%
Precision: 0.4420 | Recall: 0.4746 | F1 Score: 0.3838
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({1: 956, 0: 904})

Validation loss did not improve. Patience: 9/15

Epoch 12/50
Train Loss: 0.0125 | Train Acc: 99.84%
Val Loss: 10.3658 | Val Acc: 49.06%
Precision: 0.3811 | Recall: 0.4727 | F1 Score: 0.3544
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({0: 963, 1: 897})

Validation loss did not improve. Patience: 10/15

Epoch 13/50
Train Loss: 0.0076 | Train Acc: 99.95%
Val Loss: 15.2015 | Val Acc: 44.38%
Precision: 0.3788 | Recall: 0.4741 | F1 Score: 0.3318
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({1: 953, 0: 907})

Validation loss did not improve. Patience: 11/15

Epoch 14/50
Train Loss: 0.0093 | Train Acc: 99.84%
Val Loss: 10.4586 | Val Acc: 45.62%
Precision: 0.3273 | Recall: 0.4351 | F1 Score: 0.3385
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({1: 932, 0: 928})

Validation loss did not improve. Patience: 12/15

Epoch 15/50
Train Loss: 0.0166 | Train Acc: 99.62%
Val Loss: 10.2945 | Val Acc: 50.31%
Precision: 0.4317 | Recall: 0.4709 | F1 Score: 0.3955
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 15: 93
Label distribution in training epoch: Counter({1: 945, 0: 915})

Validation loss did not improve. Patience: 13/15

Epoch 16/50
Train Loss: 0.0027 | Train Acc: 99.95%
Val Loss: 5.9199 | Val Acc: 42.97%
Precision: 0.3514 | Recall: 0.4472 | F1 Score: 0.3336
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 16: 93
Label distribution in training epoch: Counter({0: 932, 1: 928})

Validation loss did not improve. Patience: 14/15

Epoch 17/50
Train Loss: 0.0028 | Train Acc: 99.95%
Val Loss: 9.1719 | Val Acc: 48.44%
Precision: 0.4138 | Recall: 0.4803 | F1 Score: 0.3579
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 17: 93
Label distribution in training epoch: Counter({0: 945, 1: 915})

Validation loss did not improve. Patience: 15/15

Early stopping triggered after 17 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 2h 52m 5s ###########
Test Accuracy on 640 images: 52.66%
AUC: 0.6719
Class 0-non-cancer: Precision: 0.54, Recall: 0.89, F1-Score: 0.67
Class 1-cancer: Precision: 0.37, Recall: 0.08, F1-Score: 0.13
