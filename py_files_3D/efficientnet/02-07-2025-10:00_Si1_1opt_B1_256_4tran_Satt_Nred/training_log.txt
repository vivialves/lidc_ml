

==== Training started at 2025-07-02 10:00:41.307508 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.6939 | Train Acc: 54.84%
Val Loss: 0.6938 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 56
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.7019 | Train Acc: 46.24%
Val Loss: 0.6931 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 58
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 3/50
Train Loss: 0.7013 | Train Acc: 46.24%
Val Loss: 0.6928 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 56
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 4/50
Train Loss: 0.6973 | Train Acc: 40.86%
Val Loss: 0.6928 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 58
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 1/20

Epoch 5/50
Train Loss: 0.6983 | Train Acc: 46.24%
Val Loss: 0.6915 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 6/50
Train Loss: 0.6928 | Train Acc: 54.84%
Val Loss: 0.6947 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 58
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 1/20

Epoch 7/50
Train Loss: 0.6986 | Train Acc: 47.31%
Val Loss: 0.6923 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 2/20

Epoch 8/50
Train Loss: 0.6780 | Train Acc: 63.44%
Val Loss: 0.6941 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 56
Label distribution in training epoch: Counter({1: 60, 0: 33})

Validation loss did not improve. Patience: 3/20

Epoch 9/50
Train Loss: 0.7075 | Train Acc: 47.31%
Val Loss: 0.6950 | Val Acc: 40.62%
Precision: 0.4464 | Recall: 0.4757 | F1 Score: 0.3552
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 54
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 4/20

Epoch 10/50
Train Loss: 0.7054 | Train Acc: 49.46%
Val Loss: 0.6970 | Val Acc: 46.88%
Precision: 0.2419 | Recall: 0.4688 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 57
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 5/20

Epoch 11/50
Train Loss: 0.7018 | Train Acc: 37.63%
Val Loss: 0.7008 | Val Acc: 46.88%
Precision: 0.2419 | Recall: 0.4688 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 61
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 6/20

Epoch 12/50
Train Loss: 0.6909 | Train Acc: 50.54%
Val Loss: 0.6956 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 57
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 7/20

Epoch 13/50
Train Loss: 0.6995 | Train Acc: 48.39%
Val Loss: 0.6661 | Val Acc: 53.12%
Precision: 0.2742 | Recall: 0.4722 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 55
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 14/50
Train Loss: 0.6969 | Train Acc: 52.69%
Val Loss: 0.6982 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 1/20

Epoch 15/50
Train Loss: 0.6967 | Train Acc: 48.39%
Val Loss: 0.7528 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 56
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 2/20

Epoch 16/50
Train Loss: 0.6939 | Train Acc: 52.69%
Val Loss: 0.6788 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 58
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 3/20

Epoch 17/50
Train Loss: 0.7006 | Train Acc: 48.39%
Val Loss: 0.7049 | Val Acc: 46.88%
Precision: 0.4773 | Recall: 0.4804 | F1 Score: 0.4555
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 57
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 4/20

Epoch 18/50
Train Loss: 0.6942 | Train Acc: 53.76%
Val Loss: 0.9212 | Val Acc: 53.12%
Precision: 0.4792 | Recall: 0.4838 | F1 Score: 0.4684
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 5/20

Epoch 19/50
Train Loss: 0.6992 | Train Acc: 47.31%
Val Loss: 1.1364 | Val Acc: 65.62%
Precision: 0.6389 | Recall: 0.6515 | F1 Score: 0.6390
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 58
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 6/20

Epoch 20/50
Train Loss: 0.6879 | Train Acc: 52.69%
Val Loss: 0.7043 | Val Acc: 59.38%
Precision: 0.5850 | Recall: 0.5833 | F1 Score: 0.5836
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 7/20

Epoch 21/50
Train Loss: 0.6895 | Train Acc: 54.84%
Val Loss: 0.8416 | Val Acc: 43.75%
Precision: 0.4396 | Recall: 0.4510 | F1 Score: 0.4170
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 57
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 8/20

Epoch 22/50
Train Loss: 0.6929 | Train Acc: 52.69%
Val Loss: 0.8330 | Val Acc: 50.00%
Precision: 0.4229 | Recall: 0.4453 | F1 Score: 0.4182
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 9/20

Epoch 23/50
Train Loss: 0.7105 | Train Acc: 33.33%
Val Loss: 0.7163 | Val Acc: 53.12%
Precision: 0.4425 | Recall: 0.4802 | F1 Score: 0.3992
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 59
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 10/20

Epoch 24/50
Train Loss: 0.6878 | Train Acc: 55.91%
Val Loss: 0.8475 | Val Acc: 43.75%
Precision: 0.4416 | Recall: 0.4471 | F1 Score: 0.4286
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 56
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 11/20

Epoch 25/50
Train Loss: 0.6894 | Train Acc: 55.91%
Val Loss: 0.8487 | Val Acc: 53.12%
Precision: 0.5314 | Recall: 0.5312 | F1 Score: 0.5308
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 63
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 12/20

Epoch 26/50
Train Loss: 0.6990 | Train Acc: 46.24%
Val Loss: 0.7484 | Val Acc: 43.75%
Precision: 0.4343 | Recall: 0.4549 | F1 Score: 0.4000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 53
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 13/20

Epoch 27/50
Train Loss: 0.6956 | Train Acc: 46.24%
Val Loss: 0.6853 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 59
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 14/20

Epoch 28/50
Train Loss: 0.7005 | Train Acc: 48.39%
Val Loss: 0.6871 | Val Acc: 53.12%
Precision: 0.2742 | Recall: 0.4722 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 58
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 15/20

Epoch 29/50
Train Loss: 0.6978 | Train Acc: 52.69%
Val Loss: 0.6783 | Val Acc: 62.50%
Precision: 0.3125 | Recall: 0.5000 | F1 Score: 0.3846
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 29: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 16/20

Epoch 30/50
Train Loss: 0.6867 | Train Acc: 54.84%
Val Loss: 0.7080 | Val Acc: 50.00%
Precision: 0.2759 | Recall: 0.4211 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 30: 59
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 17/20

Epoch 31/50
Train Loss: 0.6967 | Train Acc: 46.24%
Val Loss: 0.6970 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 31: 55
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 18/20

Epoch 32/50
Train Loss: 0.6930 | Train Acc: 45.16%
Val Loss: 0.6944 | Val Acc: 43.75%
Precision: 0.4667 | Recall: 0.4921 | F1 Score: 0.3455
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 32: 61
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 19/20

Epoch 33/50
Train Loss: 0.6970 | Train Acc: 40.86%
Val Loss: 0.6876 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 33: 59
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 20/20

Early stopping triggered after 33 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 0h 16m 33s ###########
Test Accuracy on 32 images: 40.62%
AUC: 0.3059
Class 0-non-cancer: Precision: 0.61, Recall: 0.95, F1-Score: 0.75
Class 1-cancer: Precision: 0.00, Recall: 0.00, F1-Score: 0.00
