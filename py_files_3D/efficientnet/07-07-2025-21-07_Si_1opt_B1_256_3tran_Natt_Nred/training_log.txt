

==== Training started at 2025-07-07 21:07:31.042041 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.7222 | Train Acc: 37.63%
Val Loss: 0.6935 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 64
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 2/50
Train Loss: 0.7137 | Train Acc: 40.86%
Val Loss: 0.6931 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 3/50
Train Loss: 0.6995 | Train Acc: 54.84%
Val Loss: 0.6919 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 56
Label distribution in training epoch: Counter({0: 55, 1: 38})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 4/50
Train Loss: 0.7026 | Train Acc: 50.54%
Val Loss: 0.6859 | Val Acc: 68.75%
Precision: 0.3438 | Recall: 0.5000 | F1 Score: 0.4074
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 64
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 5/50
Train Loss: 0.7100 | Train Acc: 49.46%
Val Loss: 0.6914 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 61
Label distribution in training epoch: Counter({1: 55, 0: 38})

Validation loss did not improve. Patience: 1/15

Epoch 6/50
Train Loss: 0.6943 | Train Acc: 50.54%
Val Loss: 0.6898 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 56
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 2/15

Epoch 7/50
Train Loss: 0.6786 | Train Acc: 56.99%
Val Loss: 0.6823 | Val Acc: 68.75%
Precision: 0.3438 | Recall: 0.5000 | F1 Score: 0.4074
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 55
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 8/50
Train Loss: 0.7009 | Train Acc: 53.76%
Val Loss: 0.6935 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 54
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 1/15

Epoch 9/50
Train Loss: 0.7049 | Train Acc: 50.54%
Val Loss: 0.7085 | Val Acc: 31.25%
Precision: 0.1667 | Recall: 0.4167 | F1 Score: 0.2381
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 57
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 2/15

Epoch 10/50
Train Loss: 0.7014 | Train Acc: 49.46%
Val Loss: 0.7357 | Val Acc: 46.88%
Precision: 0.2679 | Recall: 0.3947 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 3/15

Epoch 11/50
Train Loss: 0.7078 | Train Acc: 45.16%
Val Loss: 0.6848 | Val Acc: 59.38%
Precision: 0.7833 | Recall: 0.5667 | F1 Score: 0.4793
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 64
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 4/15

Epoch 12/50
Train Loss: 0.6992 | Train Acc: 53.76%
Val Loss: 1.2802 | Val Acc: 59.38%
Precision: 0.5917 | Recall: 0.5863 | F1 Score: 0.5836
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 62
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 5/15

Epoch 13/50
Train Loss: 0.7226 | Train Acc: 36.56%
Val Loss: 0.6392 | Val Acc: 46.88%
Precision: 0.2586 | Recall: 0.4167 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 57
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 14/50
Train Loss: 0.7250 | Train Acc: 35.48%
Val Loss: 0.7442 | Val Acc: 53.12%
Precision: 0.5971 | Recall: 0.5675 | F1 Score: 0.5077
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 55
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 1/15

Epoch 15/50
Train Loss: 0.7065 | Train Acc: 46.24%
Val Loss: 0.8676 | Val Acc: 43.75%
Precision: 0.3829 | Recall: 0.4196 | F1 Score: 0.3766
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 2/15

Epoch 16/50
Train Loss: 0.6835 | Train Acc: 52.69%
Val Loss: 0.7358 | Val Acc: 56.25%
Precision: 0.3103 | Recall: 0.4286 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 63
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 3/15

Epoch 17/50
Train Loss: 0.6942 | Train Acc: 51.61%
Val Loss: 1.6981 | Val Acc: 65.62%
Precision: 0.6583 | Recall: 0.6490 | F1 Score: 0.6476
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 58
Label distribution in training epoch: Counter({1: 55, 0: 38})

Validation loss did not improve. Patience: 4/15

Epoch 18/50
Train Loss: 0.7054 | Train Acc: 48.39%
Val Loss: 1.1245 | Val Acc: 56.25%
Precision: 0.5725 | Recall: 0.5801 | F1 Score: 0.5556
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 56
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 5/15

Epoch 19/50
Train Loss: 0.7159 | Train Acc: 46.24%
Val Loss: 1.9092 | Val Acc: 46.88%
Precision: 0.4583 | Recall: 0.4608 | F1 Score: 0.4555
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 61
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 6/15

Epoch 20/50
Train Loss: 0.7056 | Train Acc: 44.09%
Val Loss: 0.8160 | Val Acc: 21.88%
Precision: 0.1860 | Recall: 0.2421 | F1 Score: 0.1992
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 56
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 7/15

Epoch 21/50
Train Loss: 0.7146 | Train Acc: 48.39%
Val Loss: 1.3056 | Val Acc: 53.12%
Precision: 0.5275 | Recall: 0.5278 | F1 Score: 0.5271
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 59
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 8/15

Epoch 22/50
Train Loss: 0.7052 | Train Acc: 47.31%
Val Loss: 436.4297 | Val Acc: 34.38%
Precision: 0.6613 | Recall: 0.5227 | F1 Score: 0.2874
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 9/15

Epoch 23/50
Train Loss: 0.6989 | Train Acc: 52.69%
Val Loss: 5.3160 | Val Acc: 62.50%
Precision: 0.6235 | Recall: 0.6196 | F1 Score: 0.6190
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 10/15

Epoch 24/50
Train Loss: 0.7098 | Train Acc: 49.46%
Val Loss: 1.2000 | Val Acc: 65.62%
Precision: 0.7244 | Recall: 0.6373 | F1 Score: 0.6102
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 57
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 11/15

Epoch 25/50
Train Loss: 0.6916 | Train Acc: 51.61%
Val Loss: 1.3897 | Val Acc: 50.00%
Precision: 0.5079 | Recall: 0.5079 | F1 Score: 0.5000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 60
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 12/15

Epoch 26/50
Train Loss: 0.6836 | Train Acc: 52.69%
Val Loss: 0.6726 | Val Acc: 71.88%
Precision: 0.7171 | Recall: 0.6583 | F1 Score: 0.6632
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 13/15

Epoch 27/50
Train Loss: 0.6828 | Train Acc: 56.99%
Val Loss: 3.4019 | Val Acc: 53.12%
Precision: 0.5346 | Recall: 0.5312 | F1 Score: 0.5195
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 54
Label distribution in training epoch: Counter({1: 57, 0: 36})

Validation loss did not improve. Patience: 14/15

Epoch 28/50
Train Loss: 0.7022 | Train Acc: 44.09%
Val Loss: 1.0941 | Val Acc: 59.38%
Precision: 0.4829 | Recall: 0.4864 | F1 Score: 0.4793
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 15/15

Early stopping triggered after 28 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth for final metrics.
######## Training Finished in 0h 13m 51s ###########
Test Accuracy on 32 images: 37.50%
AUC: 0.5263
Class 0-non-cancer: Precision: 0.52, Recall: 0.94, F1-Score: 0.67
Class 1-cancer: Precision: 0.00, Recall: 0.00, F1-Score: 0.00
