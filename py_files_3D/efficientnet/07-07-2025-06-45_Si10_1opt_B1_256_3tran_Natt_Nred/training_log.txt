

==== Training started at 2025-07-07 06:45:14.256552 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.7008 | Train Acc: 50.65%
Val Loss: 0.6813 | Val Acc: 47.19%
Precision: 0.2359 | Recall: 0.5000 | F1 Score: 0.3206
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 92
Label distribution in training epoch: Counter({0: 480, 1: 450})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 2/50
Train Loss: 0.6998 | Train Acc: 49.03%
Val Loss: 1.0091 | Val Acc: 47.19%
Precision: 0.4625 | Recall: 0.4805 | F1 Score: 0.4054
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({1: 475, 0: 455})

Validation loss did not improve. Patience: 1/15

Epoch 3/50
Train Loss: 0.7003 | Train Acc: 50.32%
Val Loss: 1.0821 | Val Acc: 55.62%
Precision: 0.5741 | Recall: 0.5392 | F1 Score: 0.4864
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({1: 470, 0: 460})

Validation loss did not improve. Patience: 2/15

Epoch 4/50
Train Loss: 0.6992 | Train Acc: 49.03%
Val Loss: 0.8877 | Val Acc: 48.44%
Precision: 0.4306 | Recall: 0.4722 | F1 Score: 0.3843
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({1: 485, 0: 445})

Validation loss did not improve. Patience: 3/15

Epoch 5/50
Train Loss: 0.6941 | Train Acc: 51.18%
Val Loss: 0.6677 | Val Acc: 46.25%
Precision: 0.2313 | Recall: 0.5000 | F1 Score: 0.3162
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({1: 484, 0: 446})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth

Epoch 6/50
Train Loss: 0.6935 | Train Acc: 52.69%
Val Loss: 1.3651 | Val Acc: 50.31%
Precision: 0.4660 | Recall: 0.4766 | F1 Score: 0.4432
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({0: 481, 1: 449})

Validation loss did not improve. Patience: 1/15

Epoch 7/50
Train Loss: 0.6930 | Train Acc: 52.58%
Val Loss: 1.6000 | Val Acc: 45.94%
Precision: 0.4323 | Recall: 0.4413 | F1 Score: 0.4280
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({1: 467, 0: 463})

Validation loss did not improve. Patience: 2/15

Epoch 8/50
Train Loss: 0.6877 | Train Acc: 55.16%
Val Loss: 0.7535 | Val Acc: 51.56%
Precision: 0.5070 | Recall: 0.5055 | F1 Score: 0.4825
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({0: 476, 1: 454})

Validation loss did not improve. Patience: 3/15

Epoch 9/50
Train Loss: 0.6876 | Train Acc: 53.76%
Val Loss: 0.7017 | Val Acc: 51.56%
Precision: 0.5385 | Recall: 0.5131 | F1 Score: 0.4181
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({0: 477, 1: 453})

Validation loss did not improve. Patience: 4/15

Epoch 10/50
Train Loss: 0.6772 | Train Acc: 57.20%
Val Loss: 2.3602 | Val Acc: 53.44%
Precision: 0.5165 | Recall: 0.5111 | F1 Score: 0.4782
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({1: 465, 0: 465})

Validation loss did not improve. Patience: 5/15

Epoch 11/50
Train Loss: 0.6680 | Train Acc: 60.43%
Val Loss: 2.7873 | Val Acc: 50.94%
Precision: 0.5246 | Recall: 0.5207 | F1 Score: 0.4944
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({1: 473, 0: 457})

Validation loss did not improve. Patience: 6/15

Epoch 12/50
Train Loss: 0.6716 | Train Acc: 59.57%
Val Loss: 2.6197 | Val Acc: 43.12%
Precision: 0.4401 | Recall: 0.4528 | F1 Score: 0.4105
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({0: 475, 1: 455})

Validation loss did not improve. Patience: 7/15

Epoch 13/50
Train Loss: 0.6495 | Train Acc: 65.27%
Val Loss: 4.8248 | Val Acc: 50.94%
Precision: 0.4930 | Recall: 0.4941 | F1 Score: 0.4792
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({1: 476, 0: 454})

Validation loss did not improve. Patience: 8/15

Epoch 14/50
Train Loss: 0.6248 | Train Acc: 71.18%
Val Loss: 4.1628 | Val Acc: 40.31%
Precision: 0.2186 | Recall: 0.4188 | F1 Score: 0.2873
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({1: 467, 0: 463})

Validation loss did not improve. Patience: 9/15

Epoch 15/50
Train Loss: 0.5845 | Train Acc: 81.08%
Val Loss: 2.2637 | Val Acc: 43.75%
Precision: 0.2280 | Recall: 0.4575 | F1 Score: 0.3043
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 15: 93
Label distribution in training epoch: Counter({0: 469, 1: 461})

Validation loss did not improve. Patience: 10/15

Epoch 16/50
Train Loss: 0.5229 | Train Acc: 88.71%
Val Loss: 1.2563 | Val Acc: 49.06%
Precision: 0.2453 | Recall: 0.5000 | F1 Score: 0.3291
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 16: 93
Label distribution in training epoch: Counter({0: 482, 1: 448})

Validation loss did not improve. Patience: 11/15

Epoch 17/50
Train Loss: 0.4347 | Train Acc: 93.76%
Val Loss: 1.2294 | Val Acc: 54.38%
Precision: 0.2719 | Recall: 0.5000 | F1 Score: 0.3522
Current AMP scale: 8192.0
Unique augmented volumes seen in epoch 17: 93
Label distribution in training epoch: Counter({1: 468, 0: 462})

Validation loss did not improve. Patience: 12/15

Epoch 18/50
Train Loss: 0.3417 | Train Acc: 97.42%
Val Loss: 1.3714 | Val Acc: 45.62%
Precision: 0.2281 | Recall: 0.5000 | F1 Score: 0.3133
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 18: 93
Label distribution in training epoch: Counter({0: 473, 1: 457})

Validation loss did not improve. Patience: 13/15

Epoch 19/50
Train Loss: 0.2512 | Train Acc: 99.03%
Val Loss: 1.1577 | Val Acc: 51.88%
Precision: 0.2594 | Recall: 0.5000 | F1 Score: 0.3416
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 19: 93
Label distribution in training epoch: Counter({0: 477, 1: 453})

Validation loss did not improve. Patience: 14/15

Epoch 20/50
Train Loss: 0.1633 | Train Acc: 99.68%
Val Loss: 1.2244 | Val Acc: 40.31%
Precision: 0.3980 | Recall: 0.4057 | F1 Score: 0.3932
Current AMP scale: 4096.0
Unique augmented volumes seen in epoch 20: 93
Label distribution in training epoch: Counter({0: 493, 1: 437})

Validation loss did not improve. Patience: 15/15

Early stopping triggered after 20 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture_.pth for final metrics.
######## Training Finished in 1h 39m 2s ###########
Test Accuracy on 320 images: 53.75%
AUC: 0.5360
Class 0-non-cancer: Precision: 0.54, Recall: 1.00, F1-Score: 0.70
Class 1-cancer: Precision: 0.00, Recall: 0.00, F1-Score: 0.00
