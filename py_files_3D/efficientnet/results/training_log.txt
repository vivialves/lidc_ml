

==== Training started at 2025-06-15 02:00:06.493170 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.1330 | Train Acc: 95.34%
Val Loss: 0.9997 | Val Acc: 45.10%
Precision: 0.3959 | Recall: 0.4417 | F1 Score: 0.3765
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 1: 93
Label distribution in training epoch: Counter({0: 2833, 1: 2747})

Validation loss improved. Saving best model to /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.0170 | Train Acc: 99.61%
Val Loss: 0.9846 | Val Acc: 55.89%
Precision: 0.5647 | Recall: 0.5537 | F1 Score: 0.5368
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 2: 93
Label distribution in training epoch: Counter({0: 2818, 1: 2762})

Validation loss improved. Saving best model to /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 3/50
Train Loss: 0.0044 | Train Acc: 99.98%
Val Loss: 1.5236 | Val Acc: 45.52%
Precision: 0.2369 | Recall: 0.4605 | F1 Score: 0.3128
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 3: 93
Label distribution in training epoch: Counter({1: 2795, 0: 2785})

Validation loss did not improve. Patience: 1/6

Epoch 4/50
Train Loss: 0.0069 | Train Acc: 99.86%
Val Loss: 1.1548 | Val Acc: 43.18%
Precision: 0.4302 | Recall: 0.4328 | F1 Score: 0.4271
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 4: 93
Label distribution in training epoch: Counter({1: 2815, 0: 2765})

Validation loss did not improve. Patience: 2/6

Epoch 5/50
Train Loss: 0.0048 | Train Acc: 99.91%
Val Loss: 1.2543 | Val Acc: 51.93%
Precision: 0.5252 | Recall: 0.5227 | F1 Score: 0.5087
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 5: 93
Label distribution in training epoch: Counter({1: 2835, 0: 2745})

Validation loss did not improve. Patience: 3/6

Epoch 6/50
Train Loss: 0.0068 | Train Acc: 99.78%
Val Loss: 1.0089 | Val Acc: 49.64%
Precision: 0.4985 | Recall: 0.4986 | F1 Score: 0.4892
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 6: 93
Label distribution in training epoch: Counter({1: 2888, 0: 2692})

Validation loss did not improve. Patience: 4/6

Epoch 7/50
Train Loss: 0.0014 | Train Acc: 99.98%
Val Loss: 1.2043 | Val Acc: 38.23%
Precision: 0.3796 | Recall: 0.3822 | F1 Score: 0.3789
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 7: 93
Label distribution in training epoch: Counter({0: 2828, 1: 2752})

Validation loss did not improve. Patience: 5/6

Epoch 8/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 0.9076 | Val Acc: 48.70%
Precision: 0.4121 | Recall: 0.4780 | F1 Score: 0.3616
Current AMP scale: 1024.0
Unique augmented volumes seen in epoch 8: 93
Label distribution in training epoch: Counter({0: 2837, 1: 2743})

Validation loss improved. Saving best model to /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 9/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 0.9671 | Val Acc: 48.12%
Precision: 0.4362 | Recall: 0.4683 | F1 Score: 0.3975
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 9: 93
Label distribution in training epoch: Counter({1: 2795, 0: 2785})

Validation loss did not improve. Patience: 1/6

Epoch 10/50
Train Loss: 0.0003 | Train Acc: 100.00%
Val Loss: 1.7976 | Val Acc: 53.44%
Precision: 0.7611 | Recall: 0.5260 | F1 Score: 0.3924
Current AMP scale: 2048.0
Unique augmented volumes seen in epoch 10: 93
Label distribution in training epoch: Counter({1: 2806, 0: 2774})

Validation loss did not improve. Patience: 2/6

Epoch 11/50
Train Loss: 0.0118 | Train Acc: 99.61%
Val Loss: 1.4837 | Val Acc: 45.68%
Precision: 0.3959 | Recall: 0.4605 | F1 Score: 0.3599
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 11: 93
Label distribution in training epoch: Counter({0: 2811, 1: 2769})

Validation loss did not improve. Patience: 3/6

Epoch 12/50
Train Loss: 0.0031 | Train Acc: 99.91%
Val Loss: 2.2289 | Val Acc: 46.30%
Precision: 0.4455 | Recall: 0.4576 | F1 Score: 0.4280
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 12: 93
Label distribution in training epoch: Counter({1: 2807, 0: 2773})

Validation loss did not improve. Patience: 4/6

Epoch 13/50
Train Loss: 0.0028 | Train Acc: 99.93%
Val Loss: 1.6015 | Val Acc: 48.12%
Precision: 0.4418 | Recall: 0.4739 | F1 Score: 0.3930
Current AMP scale: 256.0
Unique augmented volumes seen in epoch 13: 93
Label distribution in training epoch: Counter({0: 2827, 1: 2753})

Validation loss did not improve. Patience: 5/6

Epoch 14/50
Train Loss: 0.0029 | Train Acc: 99.89%
Val Loss: 1.5466 | Val Acc: 45.42%
Precision: 0.4539 | Recall: 0.4575 | F1 Score: 0.4452
Current AMP scale: 512.0
Unique augmented volumes seen in epoch 14: 93
Label distribution in training epoch: Counter({0: 2797, 1: 2783})

Validation loss did not improve. Patience: 6/6

Early stopping triggered after 14 epochs.


Training complete.
Loading best model from /home/vivianea/projects/BrainInnov/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 3h 48m 36s ###########
Test Accuracy on 1920 images: 43.59%
AUC: 0.4644
Class 0-non-cancer: Precision: 0.49, Recall: 0.92, F1-Score: 0.64
Class 1-cancer: Precision: 0.42, Recall: 0.06, F1-Score: 0.10
