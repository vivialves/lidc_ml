

==== Training started at 2025-07-05 16:48:28.455867 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 1
Effective batch size: 4

Epoch 1/50
Train Loss: 0.6938 | Train Acc: 48.39%
Val Loss: 0.6920 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 55
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 2/50
Train Loss: 0.6921 | Train Acc: 48.39%
Val Loss: 0.6921 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 58
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 1/20

Epoch 3/50
Train Loss: 0.7077 | Train Acc: 36.56%
Val Loss: 0.6940 | Val Acc: 34.38%
Precision: 0.1719 | Recall: 0.5000 | F1 Score: 0.2558
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 62
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 2/20

Epoch 4/50
Train Loss: 0.6953 | Train Acc: 45.16%
Val Loss: 0.6933 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 65
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 3/20

Epoch 5/50
Train Loss: 0.6952 | Train Acc: 46.24%
Val Loss: 0.6918 | Val Acc: 65.62%
Precision: 0.3281 | Recall: 0.5000 | F1 Score: 0.3962
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 55
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 6/50
Train Loss: 0.6958 | Train Acc: 50.54%
Val Loss: 0.6910 | Val Acc: 68.75%
Precision: 0.3438 | Recall: 0.5000 | F1 Score: 0.4074
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 53
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 7/50
Train Loss: 0.6921 | Train Acc: 52.69%
Val Loss: 0.6891 | Val Acc: 65.62%
Precision: 0.3281 | Recall: 0.5000 | F1 Score: 0.3962
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 54
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 8/50
Train Loss: 0.6982 | Train Acc: 48.39%
Val Loss: 0.6890 | Val Acc: 59.38%
Precision: 0.2969 | Recall: 0.5000 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 58
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 9/50
Train Loss: 0.6946 | Train Acc: 49.46%
Val Loss: 0.6947 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 58
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 1/20

Epoch 10/50
Train Loss: 0.6722 | Train Acc: 63.44%
Val Loss: 6.2211 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 58
Label distribution in training epoch: Counter({1: 59, 0: 34})

Validation loss did not improve. Patience: 2/20

Epoch 11/50
Train Loss: 0.6883 | Train Acc: 54.84%
Val Loss: 5.2840 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 60
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 3/20

Epoch 12/50
Train Loss: 0.7009 | Train Acc: 49.46%
Val Loss: 2.0256 | Val Acc: 62.50%
Precision: 0.3125 | Recall: 0.5000 | F1 Score: 0.3846
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 63
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 4/20

Epoch 13/50
Train Loss: 0.6933 | Train Acc: 50.54%
Val Loss: 0.6992 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 57
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 5/20

Epoch 14/50
Train Loss: 0.6939 | Train Acc: 46.24%
Val Loss: 5.8557 | Val Acc: 40.62%
Precision: 0.4271 | Recall: 0.4250 | F1 Score: 0.4057
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 63
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 6/20

Epoch 15/50
Train Loss: 0.6921 | Train Acc: 51.61%
Val Loss: 1.4043 | Val Acc: 37.50%
Precision: 0.3765 | Recall: 0.3765 | F1 Score: 0.3750
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 7/20

Epoch 16/50
Train Loss: 0.6967 | Train Acc: 50.54%
Val Loss: 7.2435 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 59
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 8/20

Epoch 17/50
Train Loss: 0.6901 | Train Acc: 56.99%
Val Loss: 8.6040 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 61
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 9/20

Epoch 18/50
Train Loss: 0.7084 | Train Acc: 46.24%
Val Loss: 0.8964 | Val Acc: 59.38%
Precision: 0.3065 | Recall: 0.4750 | F1 Score: 0.3725
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 62
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 10/20

Epoch 19/50
Train Loss: 0.6985 | Train Acc: 46.24%
Val Loss: 3.1359 | Val Acc: 56.25%
Precision: 0.5344 | Recall: 0.5368 | F1 Score: 0.5333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 11/20

Epoch 20/50
Train Loss: 0.6939 | Train Acc: 52.69%
Val Loss: 3.2187 | Val Acc: 71.88%
Precision: 0.7682 | Recall: 0.7314 | F1 Score: 0.7117
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 58
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 12/20

Epoch 21/50
Train Loss: 0.7003 | Train Acc: 49.46%
Val Loss: 3.1432 | Val Acc: 40.62%
Precision: 0.2031 | Recall: 0.5000 | F1 Score: 0.2889
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 57
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 13/20

Epoch 22/50
Train Loss: 0.6943 | Train Acc: 50.54%
Val Loss: 2.6705 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 58
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 14/20

Epoch 23/50
Train Loss: 0.6946 | Train Acc: 51.61%
Val Loss: 1.0241 | Val Acc: 31.25%
Precision: 0.2833 | Recall: 0.2937 | F1 Score: 0.2874
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 54
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 15/20

Epoch 24/50
Train Loss: 0.7014 | Train Acc: 48.39%
Val Loss: 2.7817 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 56
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 16/20

Epoch 25/50
Train Loss: 0.6962 | Train Acc: 52.69%
Val Loss: 0.6843 | Val Acc: 71.88%
Precision: 0.7955 | Recall: 0.7632 | F1 Score: 0.7163
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 26/50
Train Loss: 0.7034 | Train Acc: 39.78%
Val Loss: 0.6342 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 65
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 27/50
Train Loss: 0.6946 | Train Acc: 51.61%
Val Loss: 0.6943 | Val Acc: 46.88%
Precision: 0.2500 | Recall: 0.4412 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 56
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 1/20

Epoch 28/50
Train Loss: 0.6959 | Train Acc: 50.54%
Val Loss: 0.5817 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 54
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 29/50
Train Loss: 0.6876 | Train Acc: 52.69%
Val Loss: 0.6321 | Val Acc: 50.00%
Precision: 0.2581 | Recall: 0.4706 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 29: 59
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 1/20

Epoch 30/50
Train Loss: 0.7002 | Train Acc: 45.16%
Val Loss: 0.8403 | Val Acc: 43.75%
Precision: 0.2593 | Recall: 0.3684 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 30: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 2/20

Epoch 31/50
Train Loss: 0.6854 | Train Acc: 53.76%
Val Loss: 1.7672 | Val Acc: 56.25%
Precision: 0.2812 | Recall: 0.5000 | F1 Score: 0.3600
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 31: 61
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 3/20

Epoch 32/50
Train Loss: 0.6972 | Train Acc: 48.39%
Val Loss: 3.7127 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 32: 55
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 4/20

Epoch 33/50
Train Loss: 0.6989 | Train Acc: 50.54%
Val Loss: 4.1983 | Val Acc: 68.75%
Precision: 0.8333 | Recall: 0.5833 | F1 Score: 0.5429
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 33: 63
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 5/20

Epoch 34/50
Train Loss: 0.6988 | Train Acc: 47.31%
Val Loss: 1.2194 | Val Acc: 53.12%
Precision: 0.5312 | Recall: 0.5314 | F1 Score: 0.5308
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 34: 56
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 6/20

Epoch 35/50
Train Loss: 0.6970 | Train Acc: 48.39%
Val Loss: 1.5401 | Val Acc: 46.88%
Precision: 0.4647 | Recall: 0.4643 | F1 Score: 0.4640
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 35: 58
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 7/20

Epoch 36/50
Train Loss: 0.6988 | Train Acc: 49.46%
Val Loss: 0.9253 | Val Acc: 59.38%
Precision: 0.6093 | Recall: 0.6071 | F1 Score: 0.5934
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 36: 63
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 8/20

Epoch 37/50
Train Loss: 0.6885 | Train Acc: 58.06%
Val Loss: 0.6172 | Val Acc: 50.00%
Precision: 0.2500 | Recall: 0.5000 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 37: 56
Label distribution in training epoch: Counter({0: 59, 1: 34})

Validation loss did not improve. Patience: 9/20

Epoch 38/50
Train Loss: 0.7055 | Train Acc: 44.09%
Val Loss: 0.6371 | Val Acc: 43.75%
Precision: 0.2188 | Recall: 0.5000 | F1 Score: 0.3043
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 38: 61
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 10/20

Epoch 39/50
Train Loss: 0.6944 | Train Acc: 44.09%
Val Loss: 0.7939 | Val Acc: 53.12%
Precision: 0.4375 | Recall: 0.4481 | F1 Score: 0.4386
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 39: 55
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 11/20

Epoch 40/50
Train Loss: 0.6909 | Train Acc: 53.76%
Val Loss: 0.7057 | Val Acc: 37.50%
Precision: 0.1875 | Recall: 0.5000 | F1 Score: 0.2727
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 40: 55
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 12/20

Epoch 41/50
Train Loss: 0.6974 | Train Acc: 47.31%
Val Loss: 0.7180 | Val Acc: 62.50%
Precision: 0.7053 | Recall: 0.6721 | F1 Score: 0.6190
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 41: 59
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 13/20

Epoch 42/50
Train Loss: 0.6876 | Train Acc: 53.76%
Val Loss: 0.6340 | Val Acc: 65.62%
Precision: 0.3281 | Recall: 0.5000 | F1 Score: 0.3962
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 42: 59
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 14/20

Epoch 43/50
Train Loss: 0.6999 | Train Acc: 47.31%
Val Loss: 2.8969 | Val Acc: 56.25%
Precision: 0.5647 | Recall: 0.5647 | F1 Score: 0.5625
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 43: 57
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 15/20

Epoch 44/50
Train Loss: 0.6963 | Train Acc: 54.84%
Val Loss: 1.7946 | Val Acc: 71.88%
Precision: 0.7188 | Recall: 0.7196 | F1 Score: 0.7185
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 44: 63
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 16/20

Epoch 45/50
Train Loss: 0.7104 | Train Acc: 36.56%
Val Loss: 0.5598 | Val Acc: 75.00%
Precision: 0.8667 | Recall: 0.6000 | F1 Score: 0.5897
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 45: 57
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth

Epoch 46/50
Train Loss: 0.6892 | Train Acc: 56.99%
Val Loss: 0.5689 | Val Acc: 75.00%
Precision: 0.3750 | Recall: 0.5000 | F1 Score: 0.4286
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 46: 57
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 1/20

Epoch 47/50
Train Loss: 0.6948 | Train Acc: 47.31%
Val Loss: 0.7729 | Val Acc: 59.38%
Precision: 0.6218 | Recall: 0.5745 | F1 Score: 0.5393
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 47: 62
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 2/20

Epoch 48/50
Train Loss: 0.6937 | Train Acc: 49.46%
Val Loss: 1.4497 | Val Acc: 59.38%
Precision: 0.5938 | Recall: 0.5941 | F1 Score: 0.5934
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 48: 63
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 3/20

Epoch 49/50
Train Loss: 0.6553 | Train Acc: 68.82%
Val Loss: 11.2117 | Val Acc: 46.88%
Precision: 0.2344 | Recall: 0.5000 | F1 Score: 0.3191
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 49: 54
Label distribution in training epoch: Counter({1: 67, 0: 26})

Validation loss did not improve. Patience: 4/20

Epoch 50/50
Train Loss: 0.7150 | Train Acc: 50.54%
Val Loss: 2.8919 | Val Acc: 40.62%
Precision: 0.2031 | Recall: 0.5000 | F1 Score: 0.2889
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 50: 55
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 5/20


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_efficientnet_pytorch3D_architecture.pth for final metrics.
######## Training Finished in 0h 25m 5s ###########
Test Accuracy on 32 images: 37.50%
AUC: 0.6392
Class 0-non-cancer: Precision: 0.59, Recall: 0.89, F1-Score: 0.71
Class 1-cancer: Precision: 0.60, Recall: 0.21, F1-Score: 0.32
