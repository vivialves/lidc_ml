

==== Sampling started at 2025-06-24 23:22:16.162218 ====


Starting Optuna optimization for Resnet3DWithSE...


==== Sampling started at 2025-06-24 23:26:53.637877 ====


Starting Optuna optimization for Resnet3DWithSE...

Optimization finished!
Number of finished trials: 50
Number of pruned trials: 37
Number of complete trials: 13

Best trial:FrozenTrial(number=0, state=1, values=[0.5625], datetime_start=datetime.datetime(2025, 6, 24, 23, 27, 14, 410884), datetime_complete=datetime.datetime(2025, 6, 24, 23, 30, 12, 137660), params={'lr': 0.009905761217784408, 'optimizer': 'SGD', 'batch_size': 1, 'epochs': 18, 'weight_decay': 0.000429724331679506, 'gradient_clipping_norm': 2.6, 'attention_reduction_ratio': 8, 'fc_dropout_rate': 0.4, 'layer4_dropout_rate': 0.5}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.375, 1: 0.5, 2: 0.375, 3: 0.40625, 4: 0.6875, 5: 0.5625, 6: 0.5625, 7: 0.46875, 8: 0.46875, 9: 0.59375, 10: 0.6875, 11: 0.5, 12: 0.5625, 13: 0.53125, 14: 0.75, 15: 0.65625, 16: 0.5625, 17: 0.5625}, distributions={'lr': FloatDistribution(high=0.01, log=True, low=1e-05, step=None), 'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop', 'SGD')), 'batch_size': CategoricalDistribution(choices=(1, 2, 4, 8)), 'epochs': IntDistribution(high=20, log=False, low=5, step=1), 'weight_decay': FloatDistribution(high=0.001, log=True, low=1e-06, step=None), 'gradient_clipping_norm': FloatDistribution(high=5.0, log=False, low=0.1, step=0.1), 'attention_reduction_ratio': CategoricalDistribution(choices=(2, 4, 8, 16)), 'fc_dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=0.1), 'layer4_dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=0.1)}, trial_id=0, value=None)
    lr: 0.009905761217784408
    optimizer: SGD
    batch_size: 1
    epochs: 18
    weight_decay: 0.000429724331679506
    gradient_clipping_norm: 2.6
    attention_reduction_ratio: 8
    fc_dropout_rate: 0.4
    layer4_dropout_rate: 0.5
######## Training LR Finished in 0h 43m 2s ###########
