

==== Training started at 2025-07-15 13:30:29.253630 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 4
Effective batch size: 16

Epoch 1/100
Train Loss: 0.7138 | Train Acc: 56.99%
Val Loss: 0.7554 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 53
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth

Epoch 2/100
Train Loss: 0.6641 | Train Acc: 66.67%
Val Loss: 0.9380 | Val Acc: 43.75%
Precision: 0.5037 | Recall: 0.5020 | F1 Score: 0.4000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 63
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 1/50

Epoch 3/100
Train Loss: 0.6923 | Train Acc: 56.99%
Val Loss: 0.7330 | Val Acc: 53.12%
Precision: 0.5583 | Recall: 0.5567 | F1 Score: 0.5308
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 55
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth

Epoch 4/100
Train Loss: 0.6244 | Train Acc: 67.74%
Val Loss: 0.7615 | Val Acc: 43.75%
Precision: 0.4534 | Recall: 0.4534 | F1 Score: 0.4375
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 1/50

Epoch 5/100
Train Loss: 0.6068 | Train Acc: 69.89%
Val Loss: 0.8657 | Val Acc: 56.25%
Precision: 0.5686 | Recall: 0.5709 | F1 Score: 0.5608
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 56
Label distribution in training epoch: Counter({1: 56, 0: 37})

Validation loss did not improve. Patience: 2/50

Epoch 6/100
Train Loss: 0.5548 | Train Acc: 73.12%
Val Loss: 0.8233 | Val Acc: 62.50%
Precision: 0.6111 | Recall: 0.6167 | F1 Score: 0.6113
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 59
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 3/50

Epoch 7/100
Train Loss: 0.5385 | Train Acc: 74.19%
Val Loss: 1.1108 | Val Acc: 34.38%
Precision: 0.3431 | Recall: 0.3438 | F1 Score: 0.3431
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 56
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 4/50

Epoch 8/100
Train Loss: 0.5172 | Train Acc: 78.49%
Val Loss: 0.7262 | Val Acc: 56.25%
Precision: 0.5686 | Recall: 0.5709 | F1 Score: 0.5608
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 62
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth

Epoch 9/100
Train Loss: 0.4804 | Train Acc: 80.65%
Val Loss: 0.7925 | Val Acc: 46.88%
Precision: 0.4688 | Recall: 0.4686 | F1 Score: 0.4682
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 56
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 1/50

Epoch 10/100
Train Loss: 0.4759 | Train Acc: 77.42%
Val Loss: 0.9912 | Val Acc: 56.25%
Precision: 0.5647 | Recall: 0.5647 | F1 Score: 0.5625
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 61
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 2/50

Epoch 11/100
Train Loss: 0.4333 | Train Acc: 84.95%
Val Loss: 1.0179 | Val Acc: 50.00%
Precision: 0.5182 | Recall: 0.5182 | F1 Score: 0.5000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 60
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 3/50

Epoch 12/100
Train Loss: 0.4165 | Train Acc: 76.34%
Val Loss: 0.8199 | Val Acc: 65.62%
Precision: 0.6310 | Recall: 0.6594 | F1 Score: 0.6267
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 61
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 4/50

Epoch 13/100
Train Loss: 0.3653 | Train Acc: 83.87%
Val Loss: 1.2218 | Val Acc: 40.62%
Precision: 0.4591 | Recall: 0.4610 | F1 Score: 0.4057
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 5/50

Epoch 14/100
Train Loss: 0.2798 | Train Acc: 90.32%
Val Loss: 0.9908 | Val Acc: 53.12%
Precision: 0.5119 | Recall: 0.5130 | F1 Score: 0.5077
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 58
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 6/50

Epoch 15/100
Train Loss: 0.2819 | Train Acc: 91.40%
Val Loss: 1.1523 | Val Acc: 50.00%
Precision: 0.6071 | Recall: 0.5476 | F1 Score: 0.4459
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 15: 61
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 7/50

Epoch 16/100
Train Loss: 0.3361 | Train Acc: 87.10%
Val Loss: 1.3731 | Val Acc: 53.12%
Precision: 0.5833 | Recall: 0.5510 | F1 Score: 0.4910
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 16: 62
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 8/50

Epoch 17/100
Train Loss: 0.0963 | Train Acc: 98.92%
Val Loss: 1.2853 | Val Acc: 56.25%
Precision: 0.5608 | Recall: 0.5608 | F1 Score: 0.5608
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 17: 58
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 9/50

Epoch 18/100
Train Loss: 0.2072 | Train Acc: 90.32%
Val Loss: 1.5766 | Val Acc: 50.00%
Precision: 0.7419 | Recall: 0.5294 | F1 Score: 0.3816
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 18: 57
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 10/50

Epoch 19/100
Train Loss: 0.1911 | Train Acc: 91.40%
Val Loss: 1.2652 | Val Acc: 68.75%
Precision: 0.6909 | Recall: 0.6667 | F1 Score: 0.6667
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 19: 57
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 11/50

Epoch 20/100
Train Loss: 0.1844 | Train Acc: 95.70%
Val Loss: 1.3738 | Val Acc: 62.50%
Precision: 0.6715 | Recall: 0.6392 | F1 Score: 0.6113
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 20: 60
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 12/50

Epoch 21/100
Train Loss: 0.2653 | Train Acc: 91.40%
Val Loss: 1.7757 | Val Acc: 40.62%
Precision: 0.4045 | Recall: 0.4176 | F1 Score: 0.3914
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 21: 57
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 13/50

Epoch 22/100
Train Loss: 0.2101 | Train Acc: 94.62%
Val Loss: 1.4771 | Val Acc: 56.25%
Precision: 0.5709 | Recall: 0.5686 | F1 Score: 0.5608
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 22: 53
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 14/50

Epoch 23/100
Train Loss: 0.2867 | Train Acc: 88.17%
Val Loss: 1.1954 | Val Acc: 50.00%
Precision: 0.4939 | Recall: 0.4941 | F1 Score: 0.4921
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 23: 62
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 15/50

Epoch 24/100
Train Loss: 0.2528 | Train Acc: 92.47%
Val Loss: 1.6567 | Val Acc: 59.38%
Precision: 0.5583 | Recall: 0.5606 | F1 Score: 0.5589
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 24: 55
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 16/50

Epoch 25/100
Train Loss: 0.1905 | Train Acc: 93.55%
Val Loss: 1.7214 | Val Acc: 53.12%
Precision: 0.5324 | Recall: 0.5312 | F1 Score: 0.5271
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 25: 57
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 17/50

Epoch 26/100
Train Loss: 0.1478 | Train Acc: 91.40%
Val Loss: 1.4491 | Val Acc: 59.38%
Precision: 0.5483 | Recall: 0.5417 | F1 Score: 0.5393
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 26: 59
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 18/50

Epoch 27/100
Train Loss: 0.2280 | Train Acc: 90.32%
Val Loss: 1.9272 | Val Acc: 46.88%
Precision: 0.4563 | Recall: 0.4555 | F1 Score: 0.4555
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 27: 58
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 19/50

Epoch 28/100
Train Loss: 0.1824 | Train Acc: 92.47%
Val Loss: 1.4559 | Val Acc: 53.12%
Precision: 0.5208 | Recall: 0.5157 | F1 Score: 0.4910
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 28: 60
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 20/50

Epoch 29/100
Train Loss: 0.1216 | Train Acc: 94.62%
Val Loss: 1.4526 | Val Acc: 50.00%
Precision: 0.5020 | Recall: 0.5020 | F1 Score: 0.5000
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 29: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 21/50

Epoch 30/100
Train Loss: 0.3770 | Train Acc: 83.87%
Val Loss: 1.3623 | Val Acc: 68.75%
Precision: 0.6863 | Recall: 0.6863 | F1 Score: 0.6863
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 30: 57
Label distribution in training epoch: Counter({1: 56, 0: 37})

Validation loss did not improve. Patience: 22/50

Epoch 31/100
Train Loss: 0.2226 | Train Acc: 89.25%
Val Loss: 1.4498 | Val Acc: 62.50%
Precision: 0.7051 | Recall: 0.6250 | F1 Score: 0.5844
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 31: 55
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 23/50

Epoch 32/100
Train Loss: 0.1397 | Train Acc: 94.62%
Val Loss: 1.8393 | Val Acc: 59.38%
Precision: 0.5833 | Recall: 0.5850 | F1 Score: 0.5836
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 32: 56
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 24/50

Epoch 33/100
Train Loss: 0.2303 | Train Acc: 93.55%
Val Loss: 2.3864 | Val Acc: 43.75%
Precision: 0.4365 | Recall: 0.4375 | F1 Score: 0.4353
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 33: 58
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 25/50

Epoch 34/100
Train Loss: 0.1294 | Train Acc: 96.77%
Val Loss: 1.9413 | Val Acc: 43.75%
Precision: 0.4500 | Recall: 0.4524 | F1 Score: 0.4353
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 34: 56
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 26/50

Epoch 35/100
Train Loss: 0.3124 | Train Acc: 86.02%
Val Loss: 2.0826 | Val Acc: 40.62%
Precision: 0.4150 | Recall: 0.4167 | F1 Score: 0.4057
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 35: 61
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 27/50

Epoch 36/100
Train Loss: 0.2619 | Train Acc: 92.47%
Val Loss: 3.1373 | Val Acc: 37.50%
Precision: 0.4364 | Recall: 0.4364 | F1 Score: 0.3750
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 36: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 28/50

Epoch 37/100
Train Loss: 0.1064 | Train Acc: 94.62%
Val Loss: 1.1036 | Val Acc: 65.62%
Precision: 0.6250 | Recall: 0.6299 | F1 Score: 0.6267
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 37: 63
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 29/50

Epoch 38/100
Train Loss: 0.1995 | Train Acc: 93.55%
Val Loss: 2.6649 | Val Acc: 37.50%
Precision: 0.3651 | Recall: 0.3651 | F1 Score: 0.3651
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 38: 58
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 30/50

Epoch 39/100
Train Loss: 0.0731 | Train Acc: 96.77%
Val Loss: 2.3288 | Val Acc: 53.12%
Precision: 0.5353 | Recall: 0.5357 | F1 Score: 0.5308
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 39: 60
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 31/50

Epoch 40/100
Train Loss: 0.1025 | Train Acc: 95.70%
Val Loss: 2.3199 | Val Acc: 28.12%
Precision: 0.2733 | Recall: 0.2812 | F1 Score: 0.2749
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 40: 57
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 32/50

Epoch 41/100
Train Loss: 0.0864 | Train Acc: 97.85%
Val Loss: 2.9608 | Val Acc: 21.88%
Precision: 0.2262 | Recall: 0.2206 | F1 Score: 0.2180
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 41: 56
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 33/50

Epoch 42/100
Train Loss: 0.1160 | Train Acc: 96.77%
Val Loss: 2.1475 | Val Acc: 46.88%
Precision: 0.4792 | Recall: 0.4843 | F1 Score: 0.4421
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 42: 57
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 34/50

Epoch 43/100
Train Loss: 0.0692 | Train Acc: 98.92%
Val Loss: 2.0994 | Val Acc: 50.00%
Precision: 0.5000 | Recall: 0.5000 | F1 Score: 0.5000
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 43: 58
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 35/50

Epoch 44/100
Train Loss: 0.0840 | Train Acc: 97.85%
Val Loss: 2.7942 | Val Acc: 37.50%
Precision: 0.2917 | Recall: 0.3413 | F1 Score: 0.3074
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 44: 59
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 36/50

Epoch 45/100
Train Loss: 0.1297 | Train Acc: 95.70%
Val Loss: 3.2151 | Val Acc: 25.00%
Precision: 0.2364 | Recall: 0.2698 | F1 Score: 0.2381
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 45: 63
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 37/50

Epoch 46/100
Train Loss: 0.1629 | Train Acc: 93.55%
Val Loss: 2.6585 | Val Acc: 37.50%
Precision: 0.3571 | Recall: 0.3500 | F1 Score: 0.3522
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 46: 63
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 38/50

Epoch 47/100
Train Loss: 0.2227 | Train Acc: 92.47%
Val Loss: 3.2001 | Val Acc: 37.50%
Precision: 0.3563 | Recall: 0.4494 | F1 Score: 0.3074
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 47: 53
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 39/50

Epoch 48/100
Train Loss: 0.0848 | Train Acc: 96.77%
Val Loss: 2.4699 | Val Acc: 37.50%
Precision: 0.3804 | Recall: 0.3765 | F1 Score: 0.3725
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 48: 60
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 40/50

Epoch 49/100
Train Loss: 0.0621 | Train Acc: 98.92%
Val Loss: 2.2974 | Val Acc: 56.25%
Precision: 0.6000 | Recall: 0.6000 | F1 Score: 0.5625
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 49: 55
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 41/50

Epoch 50/100
Train Loss: 0.1819 | Train Acc: 93.55%
Val Loss: 1.6475 | Val Acc: 62.50%
Precision: 0.6196 | Recall: 0.6235 | F1 Score: 0.6190
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 50: 65
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 42/50

Epoch 51/100
Train Loss: 0.2198 | Train Acc: 88.17%
Val Loss: 2.3347 | Val Acc: 56.25%
Precision: 0.5709 | Recall: 0.5686 | F1 Score: 0.5608
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 51: 53
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 43/50

Epoch 52/100
Train Loss: 0.0794 | Train Acc: 96.77%
Val Loss: 3.0563 | Val Acc: 46.88%
Precision: 0.3750 | Recall: 0.4451 | F1 Score: 0.3637
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 52: 56
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 44/50

Epoch 53/100
Train Loss: 0.0878 | Train Acc: 98.92%
Val Loss: 1.5712 | Val Acc: 56.25%
Precision: 0.5357 | Recall: 0.5159 | F1 Score: 0.4589
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 53: 58
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 45/50

Epoch 54/100
Train Loss: 0.2868 | Train Acc: 90.32%
Val Loss: 2.0858 | Val Acc: 43.75%
Precision: 0.4392 | Recall: 0.4392 | F1 Score: 0.4375
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 54: 60
Label distribution in training epoch: Counter({0: 58, 1: 35})

Validation loss did not improve. Patience: 46/50

Epoch 55/100
Train Loss: 0.0822 | Train Acc: 95.70%
Val Loss: 1.8333 | Val Acc: 53.12%
Precision: 0.5357 | Recall: 0.5353 | F1 Score: 0.5308
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 55: 61
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 47/50

Epoch 56/100
Train Loss: 0.2394 | Train Acc: 91.40%
Val Loss: 2.0927 | Val Acc: 62.50%
Precision: 0.5029 | Recall: 0.5024 | F1 Score: 0.5000
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 56: 59
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 48/50

Epoch 57/100
Train Loss: 0.0367 | Train Acc: 100.00%
Val Loss: 3.3149 | Val Acc: 43.75%
Precision: 0.4343 | Recall: 0.4549 | F1 Score: 0.4000
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 57: 58
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 49/50

Epoch 58/100
Train Loss: 0.0618 | Train Acc: 97.85%
Val Loss: 3.2202 | Val Acc: 43.75%
Precision: 0.4275 | Recall: 0.4199 | F1 Score: 0.4170
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 58: 57
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 50/50

Early stopping triggered after 58 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth for final metrics.
######## Training Finished in 0h 23m 20s ###########
Test Accuracy on 32 images: 68.75%
AUC: 0.8438
Class 0-non-cancer: Precision: 0.65, Recall: 0.61, F1-Score: 0.63
Class 1-cancer: Precision: 0.53, Recall: 0.57, F1-Score: 0.55
