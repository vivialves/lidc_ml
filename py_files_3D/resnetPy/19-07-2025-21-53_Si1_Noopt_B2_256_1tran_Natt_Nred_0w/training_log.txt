

==== Training started at 2025-07-19 21:53:31.785136 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 2
Effective batch size: 8

Epoch 1/100
Train Loss: 0.6971 | Train Acc: 56.99%
Val Loss: 0.6098 | Val Acc: 65.62%
Precision: 0.6515 | Recall: 0.6389 | F1 Score: 0.6390
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 54
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth

Epoch 2/100
Train Loss: 0.6541 | Train Acc: 61.29%
Val Loss: 0.7134 | Val Acc: 59.38%
Precision: 0.5992 | Recall: 0.5980 | F1 Score: 0.5934
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 62
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 1/50

Epoch 3/100
Train Loss: 0.6861 | Train Acc: 62.37%
Val Loss: 0.7410 | Val Acc: 59.38%
Precision: 0.5902 | Recall: 0.5913 | F1 Score: 0.5901
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 2/50

Epoch 4/100
Train Loss: 0.6980 | Train Acc: 58.06%
Val Loss: 0.7472 | Val Acc: 46.88%
Precision: 0.4654 | Recall: 0.4688 | F1 Score: 0.4555
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 67
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 3/50

Epoch 5/100
Train Loss: 0.5880 | Train Acc: 74.19%
Val Loss: 0.7194 | Val Acc: 50.00%
Precision: 0.5273 | Recall: 0.5238 | F1 Score: 0.4921
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 54
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 4/50

Epoch 6/100
Train Loss: 0.6222 | Train Acc: 67.74%
Val Loss: 0.7846 | Val Acc: 59.38%
Precision: 0.6083 | Recall: 0.6020 | F1 Score: 0.5901
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 60
Label distribution in training epoch: Counter({1: 59, 0: 34})

Validation loss did not improve. Patience: 5/50

Epoch 7/100
Train Loss: 0.6508 | Train Acc: 64.52%
Val Loss: 1.0458 | Val Acc: 37.50%
Precision: 0.3943 | Recall: 0.4251 | F1 Score: 0.3522
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 59
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 6/50

Epoch 8/100
Train Loss: 0.6233 | Train Acc: 70.97%
Val Loss: 0.7125 | Val Acc: 59.38%
Precision: 0.5938 | Recall: 0.5972 | F1 Score: 0.5901
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 60
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 7/50

Epoch 9/100
Train Loss: 0.6360 | Train Acc: 61.29%
Val Loss: 0.7156 | Val Acc: 46.88%
Precision: 0.4686 | Recall: 0.4688 | F1 Score: 0.4682
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 62
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 8/50

Epoch 10/100
Train Loss: 0.5454 | Train Acc: 70.97%
Val Loss: 1.0028 | Val Acc: 53.12%
Precision: 0.6474 | Recall: 0.5931 | F1 Score: 0.5077
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 58
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 9/50

Epoch 11/100
Train Loss: 0.5730 | Train Acc: 67.74%
Val Loss: 0.9398 | Val Acc: 37.50%
Precision: 0.3429 | Recall: 0.3922 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 57
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 10/50

Epoch 12/100
Train Loss: 0.4684 | Train Acc: 76.34%
Val Loss: 1.1341 | Val Acc: 59.38%
Precision: 0.6227 | Recall: 0.6059 | F1 Score: 0.5836
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 55
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 11/50

Epoch 13/100
Train Loss: 0.5654 | Train Acc: 74.19%
Val Loss: 1.0571 | Val Acc: 40.62%
Precision: 0.4062 | Recall: 0.4059 | F1 Score: 0.4057
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 58
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 12/50

Epoch 14/100
Train Loss: 0.4988 | Train Acc: 68.82%
Val Loss: 1.0243 | Val Acc: 46.88%
Precision: 0.5628 | Recall: 0.5591 | F1 Score: 0.4682
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 59
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 13/50

Epoch 15/100
Train Loss: 0.4722 | Train Acc: 74.19%
Val Loss: 0.8636 | Val Acc: 56.25%
Precision: 0.7500 | Recall: 0.6111 | F1 Score: 0.5152
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 60
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 14/50

Epoch 16/100
Train Loss: 0.4063 | Train Acc: 81.72%
Val Loss: 1.4290 | Val Acc: 34.38%
Precision: 0.3542 | Recall: 0.3866 | F1 Score: 0.3273
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 50
Label distribution in training epoch: Counter({0: 61, 1: 32})

Validation loss did not improve. Patience: 15/50

Epoch 17/100
Train Loss: 0.5100 | Train Acc: 76.34%
Val Loss: 1.0872 | Val Acc: 37.50%
Precision: 0.3623 | Recall: 0.3882 | F1 Score: 0.3522
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 58
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 16/50

Epoch 18/100
Train Loss: 0.3605 | Train Acc: 82.80%
Val Loss: 1.2537 | Val Acc: 46.88%
Precision: 0.4500 | Recall: 0.4569 | F1 Score: 0.4421
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 58
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 17/50

Epoch 19/100
Train Loss: 0.4394 | Train Acc: 78.49%
Val Loss: 2.2783 | Val Acc: 34.38%
Precision: 0.3036 | Recall: 0.4109 | F1 Score: 0.2874
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 54
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 18/50

Epoch 20/100
Train Loss: 0.2544 | Train Acc: 92.47%
Val Loss: 1.6028 | Val Acc: 50.00%
Precision: 0.5000 | Recall: 0.5000 | F1 Score: 0.4459
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 54
Label distribution in training epoch: Counter({0: 56, 1: 37})

Validation loss did not improve. Patience: 19/50

Epoch 21/100
Train Loss: 0.3273 | Train Acc: 83.87%
Val Loss: 1.2253 | Val Acc: 50.00%
Precision: 0.4833 | Recall: 0.4841 | F1 Score: 0.4818
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 62
Label distribution in training epoch: Counter({1: 53, 0: 40})

Validation loss did not improve. Patience: 20/50

Epoch 22/100
Train Loss: 0.3139 | Train Acc: 88.17%
Val Loss: 1.2787 | Val Acc: 53.12%
Precision: 0.4943 | Recall: 0.4960 | F1 Score: 0.4684
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 22: 53
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 21/50

Epoch 23/100
Train Loss: 0.3002 | Train Acc: 92.47%
Val Loss: 1.8405 | Val Acc: 40.62%
Precision: 0.2167 | Recall: 0.4333 | F1 Score: 0.2889
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 23: 59
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 22/50

Epoch 24/100
Train Loss: 0.3510 | Train Acc: 82.80%
Val Loss: 1.0851 | Val Acc: 46.88%
Precision: 0.4643 | Recall: 0.4647 | F1 Score: 0.4640
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 24: 61
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 23/50

Epoch 25/100
Train Loss: 0.1533 | Train Acc: 94.62%
Val Loss: 1.5136 | Val Acc: 43.75%
Precision: 0.4396 | Recall: 0.4510 | F1 Score: 0.4170
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 25: 56
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 24/50

Epoch 26/100
Train Loss: 0.3618 | Train Acc: 83.87%
Val Loss: 1.8409 | Val Acc: 37.50%
Precision: 0.3492 | Recall: 0.3273 | F1 Score: 0.3333
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 26: 60
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 25/50

Epoch 27/100
Train Loss: 0.1811 | Train Acc: 93.55%
Val Loss: 1.7062 | Val Acc: 34.38%
Precision: 0.3268 | Recall: 0.3438 | F1 Score: 0.3273
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 27: 56
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 26/50

Epoch 28/100
Train Loss: 0.1738 | Train Acc: 95.70%
Val Loss: 1.9280 | Val Acc: 40.62%
Precision: 0.4250 | Recall: 0.4271 | F1 Score: 0.4057
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 28: 61
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 27/50

Epoch 29/100
Train Loss: 0.1265 | Train Acc: 95.70%
Val Loss: 1.3962 | Val Acc: 62.50%
Precision: 0.6148 | Recall: 0.5628 | F1 Score: 0.5362
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 29: 57
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 28/50

Epoch 30/100
Train Loss: 0.1155 | Train Acc: 95.70%
Val Loss: 1.5555 | Val Acc: 62.50%
Precision: 0.5833 | Recall: 0.5909 | F1 Score: 0.5844
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 30: 56
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 29/50

Epoch 31/100
Train Loss: 0.1894 | Train Acc: 92.47%
Val Loss: 1.5143 | Val Acc: 56.25%
Precision: 0.5657 | Recall: 0.5451 | F1 Score: 0.5152
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 31: 55
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 30/50

Epoch 32/100
Train Loss: 0.0669 | Train Acc: 100.00%
Val Loss: 2.0307 | Val Acc: 46.88%
Precision: 0.6600 | Recall: 0.6458 | F1 Score: 0.4682
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 32: 60
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 31/50

Epoch 33/100
Train Loss: 0.1095 | Train Acc: 95.70%
Val Loss: 1.4703 | Val Acc: 40.62%
Precision: 0.4062 | Recall: 0.4059 | F1 Score: 0.4057
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 33: 62
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 32/50

Epoch 34/100
Train Loss: 0.0840 | Train Acc: 97.85%
Val Loss: 1.3958 | Val Acc: 50.00%
Precision: 0.4833 | Recall: 0.4841 | F1 Score: 0.4818
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 34: 58
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 33/50

Epoch 35/100
Train Loss: 0.1167 | Train Acc: 95.70%
Val Loss: 3.5343 | Val Acc: 53.12%
Precision: 0.2656 | Recall: 0.5000 | F1 Score: 0.3469
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 35: 58
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 34/50

Epoch 36/100
Train Loss: 0.0863 | Train Acc: 95.70%
Val Loss: 2.1975 | Val Acc: 46.88%
Precision: 0.4688 | Recall: 0.4686 | F1 Score: 0.4682
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 36: 61
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 35/50

Epoch 37/100
Train Loss: 0.1605 | Train Acc: 94.62%
Val Loss: 1.5663 | Val Acc: 46.88%
Precision: 0.4792 | Recall: 0.4843 | F1 Score: 0.4421
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 37: 60
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 36/50

Epoch 38/100
Train Loss: 0.0896 | Train Acc: 97.85%
Val Loss: 2.5213 | Val Acc: 40.62%
Precision: 0.4250 | Recall: 0.4271 | F1 Score: 0.4057
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 38: 58
Label distribution in training epoch: Counter({0: 57, 1: 36})

Validation loss did not improve. Patience: 37/50

Epoch 39/100
Train Loss: 0.0190 | Train Acc: 100.00%
Val Loss: 1.8299 | Val Acc: 40.62%
Precision: 0.4059 | Recall: 0.4062 | F1 Score: 0.4057
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 39: 60
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 38/50

Epoch 40/100
Train Loss: 0.0517 | Train Acc: 98.92%
Val Loss: 1.9080 | Val Acc: 53.12%
Precision: 0.5275 | Recall: 0.5278 | F1 Score: 0.5271
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 40: 52
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 39/50

Epoch 41/100
Train Loss: 0.0090 | Train Acc: 100.00%
Val Loss: 3.2673 | Val Acc: 46.88%
Precision: 0.5893 | Recall: 0.5405 | F1 Score: 0.4231
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 41: 53
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 40/50

Epoch 42/100
Train Loss: 0.0191 | Train Acc: 100.00%
Val Loss: 2.3845 | Val Acc: 56.25%
Precision: 0.5357 | Recall: 0.5159 | F1 Score: 0.4589
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 42: 58
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 41/50

Epoch 43/100
Train Loss: 0.0485 | Train Acc: 98.92%
Val Loss: 3.3787 | Val Acc: 37.50%
Precision: 0.4286 | Recall: 0.4667 | F1 Score: 0.3333
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 43: 61
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 42/50

Epoch 44/100
Train Loss: 0.0101 | Train Acc: 100.00%
Val Loss: 3.1537 | Val Acc: 37.50%
Precision: 0.4091 | Recall: 0.4167 | F1 Score: 0.3725
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 44: 52
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 43/50

Epoch 45/100
Train Loss: 0.0184 | Train Acc: 98.92%
Val Loss: 4.4968 | Val Acc: 53.12%
Precision: 0.5725 | Recall: 0.5595 | F1 Score: 0.5195
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 45: 58
Label distribution in training epoch: Counter({0: 52, 1: 41})

Validation loss did not improve. Patience: 44/50

Epoch 46/100
Train Loss: 0.0041 | Train Acc: 100.00%
Val Loss: 3.5746 | Val Acc: 37.50%
Precision: 0.4231 | Recall: 0.4500 | F1 Score: 0.3522
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 46: 56
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 45/50

Epoch 47/100
Train Loss: 0.0056 | Train Acc: 100.00%
Val Loss: 2.4739 | Val Acc: 50.00%
Precision: 0.5641 | Recall: 0.5397 | F1 Score: 0.4667
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 47: 55
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 46/50

Epoch 48/100
Train Loss: 0.0130 | Train Acc: 98.92%
Val Loss: 2.9643 | Val Acc: 46.88%
Precision: 0.4722 | Recall: 0.4725 | F1 Score: 0.4682
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 48: 61
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 47/50

Epoch 49/100
Train Loss: 0.0074 | Train Acc: 100.00%
Val Loss: 2.3846 | Val Acc: 59.38%
Precision: 0.3167 | Recall: 0.4524 | F1 Score: 0.3725
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 49: 61
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 48/50

Epoch 50/100
Train Loss: 0.0060 | Train Acc: 100.00%
Val Loss: 3.1219 | Val Acc: 43.75%
Precision: 0.4416 | Recall: 0.4471 | F1 Score: 0.4286
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 50: 64
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 49/50

Epoch 51/100
Train Loss: 0.0015 | Train Acc: 100.00%
Val Loss: 2.3006 | Val Acc: 53.12%
Precision: 0.4955 | Recall: 0.4960 | F1 Score: 0.4910
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 51: 60
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 50/50

Early stopping triggered after 51 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth for final metrics.
######## Training Finished in 0h 37m 0s ###########
Test Accuracy on 32 images: 87.50%
AUC: 0.9167
AUC: 0.7437
Class 0-non-cancer: Precision: 0.62, Recall: 0.57, F1-Score: 0.59
Class 1-cancer: Precision: 0.68, Recall: 0.72, F1-Score: 0.70
