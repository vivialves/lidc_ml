

==== Training started at 2025-07-20 08:15:45.152925 ====

Using Gradient Accumulation with 4 steps.
DataLoader batch size: 2
Effective batch size: 8

Epoch 1/100
Train Loss: 0.6971 | Train Acc: 56.99%
Val Loss: 0.6346 | Val Acc: 64.06%
Precision: 0.6229 | Recall: 0.6123 | F1 Score: 0.6133
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 1: 54
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss improved. Saving best model to /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth

Epoch 2/100
Train Loss: 0.6409 | Train Acc: 60.22%
Val Loss: 0.9737 | Val Acc: 51.56%
Precision: 0.5218 | Recall: 0.5156 | F1 Score: 0.4789
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 2: 58
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 1/50

Epoch 3/100
Train Loss: 0.6263 | Train Acc: 66.67%
Val Loss: 0.7508 | Val Acc: 68.75%
Precision: 0.6981 | Recall: 0.6627 | F1 Score: 0.6607
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 3: 62
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 2/50

Epoch 4/100
Train Loss: 0.6474 | Train Acc: 64.52%
Val Loss: 0.7011 | Val Acc: 59.38%
Precision: 0.5955 | Recall: 0.5824 | F1 Score: 0.5733
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 4: 56
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 3/50

Epoch 5/100
Train Loss: 0.6275 | Train Acc: 66.67%
Val Loss: 0.6662 | Val Acc: 65.62%
Precision: 0.6588 | Recall: 0.6627 | F1 Score: 0.6549
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 5: 60
Label distribution in training epoch: Counter({1: 57, 0: 36})

Validation loss did not improve. Patience: 4/50

Epoch 6/100
Train Loss: 0.6501 | Train Acc: 63.44%
Val Loss: 0.7563 | Val Acc: 53.12%
Precision: 0.6343 | Recall: 0.5655 | F1 Score: 0.4805
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 6: 58
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 5/50

Epoch 7/100
Train Loss: 0.6096 | Train Acc: 65.59%
Val Loss: 0.7824 | Val Acc: 45.31%
Precision: 0.4625 | Recall: 0.4645 | F1 Score: 0.4498
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 7: 58
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 6/50

Epoch 8/100
Train Loss: 0.5200 | Train Acc: 77.42%
Val Loss: 0.8070 | Val Acc: 57.81%
Precision: 0.6392 | Recall: 0.6204 | F1 Score: 0.5730
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 8: 58
Label distribution in training epoch: Counter({0: 56, 1: 37})

Validation loss did not improve. Patience: 7/50

Epoch 9/100
Train Loss: 0.6372 | Train Acc: 66.67%
Val Loss: 0.7271 | Val Acc: 48.44%
Precision: 0.4579 | Recall: 0.4623 | F1 Score: 0.4544
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 9: 57
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 8/50

Epoch 10/100
Train Loss: 0.4928 | Train Acc: 75.27%
Val Loss: 0.7407 | Val Acc: 56.25%
Precision: 0.5667 | Recall: 0.5675 | F1 Score: 0.5621
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 10: 56
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 9/50

Epoch 11/100
Train Loss: 0.5214 | Train Acc: 74.19%
Val Loss: 0.9949 | Val Acc: 48.44%
Precision: 0.4775 | Recall: 0.4764 | F1 Score: 0.4740
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 11: 56
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 10/50

Epoch 12/100
Train Loss: 0.5218 | Train Acc: 73.12%
Val Loss: 0.9683 | Val Acc: 62.50%
Precision: 0.6857 | Recall: 0.6334 | F1 Score: 0.6000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 12: 59
Label distribution in training epoch: Counter({1: 54, 0: 39})

Validation loss did not improve. Patience: 11/50

Epoch 13/100
Train Loss: 0.4161 | Train Acc: 80.65%
Val Loss: 0.8601 | Val Acc: 48.44%
Precision: 0.4901 | Recall: 0.4901 | F1 Score: 0.4842
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 13: 54
Label distribution in training epoch: Counter({0: 59, 1: 34})

Validation loss did not improve. Patience: 12/50

Epoch 14/100
Train Loss: 0.5183 | Train Acc: 74.19%
Val Loss: 0.9430 | Val Acc: 46.88%
Precision: 0.4563 | Recall: 0.4555 | F1 Score: 0.4555
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 14: 63
Label distribution in training epoch: Counter({1: 50, 0: 43})

Validation loss did not improve. Patience: 13/50

Epoch 15/100
Train Loss: 0.4305 | Train Acc: 78.49%
Val Loss: 1.6342 | Val Acc: 40.62%
Precision: 0.4503 | Recall: 0.4626 | F1 Score: 0.3914
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 15: 59
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 14/50

Epoch 16/100
Train Loss: 0.4195 | Train Acc: 76.34%
Val Loss: 1.1062 | Val Acc: 45.31%
Precision: 0.4504 | Recall: 0.4511 | F1 Score: 0.4498
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 16: 51
Label distribution in training epoch: Counter({0: 59, 1: 34})

Validation loss did not improve. Patience: 15/50

Epoch 17/100
Train Loss: 0.4289 | Train Acc: 78.49%
Val Loss: 1.1182 | Val Acc: 51.56%
Precision: 0.5292 | Recall: 0.5276 | F1 Score: 0.5127
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 17: 64
Label distribution in training epoch: Counter({1: 55, 0: 38})

Validation loss did not improve. Patience: 16/50

Epoch 18/100
Train Loss: 0.3752 | Train Acc: 81.72%
Val Loss: 2.0220 | Val Acc: 46.88%
Precision: 0.5143 | Recall: 0.5105 | F1 Score: 0.4494
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 18: 55
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 17/50

Epoch 19/100
Train Loss: 0.3126 | Train Acc: 86.02%
Val Loss: 1.3699 | Val Acc: 56.25%
Precision: 0.6686 | Recall: 0.6194 | F1 Score: 0.5466
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 19: 58
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 18/50

Epoch 20/100
Train Loss: 0.3068 | Train Acc: 86.02%
Val Loss: 1.1901 | Val Acc: 48.44%
Precision: 0.4987 | Recall: 0.4990 | F1 Score: 0.4622
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 20: 54
Label distribution in training epoch: Counter({0: 55, 1: 38})

Validation loss did not improve. Patience: 19/50

Epoch 21/100
Train Loss: 0.3459 | Train Acc: 83.87%
Val Loss: 1.2066 | Val Acc: 46.88%
Precision: 0.4329 | Recall: 0.4372 | F1 Score: 0.4333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 21: 59
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 20/50

Epoch 22/100
Train Loss: 0.3752 | Train Acc: 83.87%
Val Loss: 1.2682 | Val Acc: 46.88%
Precision: 0.4611 | Recall: 0.4605 | F1 Score: 0.4603
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 22: 61
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 21/50

Epoch 23/100
Train Loss: 0.2929 | Train Acc: 86.02%
Val Loss: 1.2107 | Val Acc: 48.44%
Precision: 0.4824 | Recall: 0.4821 | F1 Score: 0.4812
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 23: 57
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 22/50

Epoch 24/100
Train Loss: 0.1870 | Train Acc: 95.70%
Val Loss: 1.5164 | Val Acc: 60.94%
Precision: 0.6214 | Recall: 0.5837 | F1 Score: 0.5622
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 24: 60
Label distribution in training epoch: Counter({1: 52, 0: 41})

Validation loss did not improve. Patience: 23/50

Epoch 25/100
Train Loss: 0.2055 | Train Acc: 90.32%
Val Loss: 1.4224 | Val Acc: 48.44%
Precision: 0.4384 | Recall: 0.4489 | F1 Score: 0.4345
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 25: 52
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 24/50

Epoch 26/100
Train Loss: 0.2180 | Train Acc: 94.62%
Val Loss: 1.3658 | Val Acc: 50.00%
Precision: 0.5079 | Recall: 0.5079 | F1 Score: 0.5000
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 26: 60
Label distribution in training epoch: Counter({0: 54, 1: 39})

Validation loss did not improve. Patience: 25/50

Epoch 27/100
Train Loss: 0.0763 | Train Acc: 100.00%
Val Loss: 1.8144 | Val Acc: 34.38%
Precision: 0.3323 | Recall: 0.3350 | F1 Score: 0.3333
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 27: 58
Label distribution in training epoch: Counter({0: 49, 1: 44})

Validation loss did not improve. Patience: 26/50

Epoch 28/100
Train Loss: 0.1069 | Train Acc: 97.85%
Val Loss: 1.8076 | Val Acc: 54.69%
Precision: 0.5531 | Recall: 0.5520 | F1 Score: 0.5459
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 28: 57
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 27/50

Epoch 29/100
Train Loss: 0.2282 | Train Acc: 90.32%
Val Loss: 1.3710 | Val Acc: 50.00%
Precision: 0.4749 | Recall: 0.4749 | F1 Score: 0.4749
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 29: 57
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 28/50

Epoch 30/100
Train Loss: 0.1746 | Train Acc: 92.47%
Val Loss: 4.1177 | Val Acc: 34.38%
Precision: 0.1746 | Recall: 0.4783 | F1 Score: 0.2558
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 30: 57
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 29/50

Epoch 31/100
Train Loss: 0.0824 | Train Acc: 98.92%
Val Loss: 1.6077 | Val Acc: 48.44%
Precision: 0.4813 | Recall: 0.4814 | F1 Score: 0.4812
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 31: 56
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 30/50

Epoch 32/100
Train Loss: 0.1911 | Train Acc: 92.47%
Val Loss: 2.2316 | Val Acc: 46.88%
Precision: 0.5000 | Recall: 0.5000 | F1 Score: 0.4494
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 32: 52
Label distribution in training epoch: Counter({1: 57, 0: 36})

Validation loss did not improve. Patience: 31/50

Epoch 33/100
Train Loss: 0.0716 | Train Acc: 98.92%
Val Loss: 2.2079 | Val Acc: 32.81%
Precision: 0.3094 | Recall: 0.3402 | F1 Score: 0.3077
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 33: 53
Label distribution in training epoch: Counter({0: 58, 1: 35})

Validation loss did not improve. Patience: 32/50

Epoch 34/100
Train Loss: 0.0845 | Train Acc: 97.85%
Val Loss: 1.3645 | Val Acc: 48.44%
Precision: 0.4814 | Recall: 0.4813 | F1 Score: 0.4812
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 34: 65
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 33/50

Epoch 35/100
Train Loss: 0.0473 | Train Acc: 98.92%
Val Loss: 2.7217 | Val Acc: 60.94%
Precision: 0.5830 | Recall: 0.5557 | F1 Score: 0.5390
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 35: 52
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 34/50

Epoch 36/100
Train Loss: 0.0448 | Train Acc: 98.92%
Val Loss: 1.9497 | Val Acc: 53.12%
Precision: 0.5495 | Recall: 0.5508 | F1 Score: 0.5308
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 36: 58
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 35/50

Epoch 37/100
Train Loss: 0.0361 | Train Acc: 98.92%
Val Loss: 1.4521 | Val Acc: 59.38%
Precision: 0.6071 | Recall: 0.6093 | F1 Score: 0.5934
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 37: 50
Label distribution in training epoch: Counter({0: 50, 1: 43})

Validation loss did not improve. Patience: 36/50

Epoch 38/100
Train Loss: 0.0182 | Train Acc: 100.00%
Val Loss: 2.2087 | Val Acc: 51.56%
Precision: 0.5523 | Recall: 0.5460 | F1 Score: 0.5098
Current AMP scale: 32768.0
Unique augmented volumes seen in epoch 38: 60
Label distribution in training epoch: Counter({0: 48, 1: 45})

Validation loss did not improve. Patience: 37/50

Epoch 39/100
Train Loss: 0.0718 | Train Acc: 96.77%
Val Loss: 3.6134 | Val Acc: 45.31%
Precision: 0.4300 | Recall: 0.4345 | F1 Score: 0.4296
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 39: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 38/50

Epoch 40/100
Train Loss: 0.0839 | Train Acc: 95.70%
Val Loss: 1.8490 | Val Acc: 50.00%
Precision: 0.4761 | Recall: 0.4775 | F1 Score: 0.4749
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 40: 65
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 39/50

Epoch 41/100
Train Loss: 0.0397 | Train Acc: 98.92%
Val Loss: 3.0220 | Val Acc: 51.56%
Precision: 0.6161 | Recall: 0.5512 | F1 Score: 0.4572
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 41: 66
Label distribution in training epoch: Counter({1: 49, 0: 44})

Validation loss did not improve. Patience: 40/50

Epoch 42/100
Train Loss: 0.0353 | Train Acc: 98.92%
Val Loss: 4.5906 | Val Acc: 43.75%
Precision: 0.2373 | Recall: 0.4242 | F1 Score: 0.3043
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 42: 60
Label distribution in training epoch: Counter({0: 47, 1: 46})

Validation loss did not improve. Patience: 41/50

Epoch 43/100
Train Loss: 0.0271 | Train Acc: 100.00%
Val Loss: 1.4034 | Val Acc: 64.06%
Precision: 0.6406 | Recall: 0.6408 | F1 Score: 0.6405
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 43: 59
Label distribution in training epoch: Counter({1: 48, 0: 45})

Validation loss did not improve. Patience: 42/50

Epoch 44/100
Train Loss: 0.0141 | Train Acc: 98.92%
Val Loss: 2.3273 | Val Acc: 51.56%
Precision: 0.5060 | Recall: 0.5060 | F1 Score: 0.5059
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 44: 61
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 43/50

Epoch 45/100
Train Loss: 0.0066 | Train Acc: 100.00%
Val Loss: 2.4067 | Val Acc: 54.69%
Precision: 0.5708 | Recall: 0.5681 | F1 Score: 0.5459
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 45: 59
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 44/50

Epoch 46/100
Train Loss: 0.0091 | Train Acc: 100.00%
Val Loss: 2.6436 | Val Acc: 40.62%
Precision: 0.4114 | Recall: 0.4128 | F1 Score: 0.4057
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 46: 57
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 45/50

Epoch 47/100
Train Loss: 0.0051 | Train Acc: 100.00%
Val Loss: 2.3613 | Val Acc: 32.81%
Precision: 0.3410 | Recall: 0.3431 | F1 Score: 0.3280
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 47: 64
Label distribution in training epoch: Counter({1: 47, 0: 46})

Validation loss did not improve. Patience: 46/50

Epoch 48/100
Train Loss: 0.0278 | Train Acc: 98.92%
Val Loss: 2.4002 | Val Acc: 46.88%
Precision: 0.4633 | Recall: 0.4585 | F1 Score: 0.4494
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 48: 54
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 47/50

Epoch 49/100
Train Loss: 0.0116 | Train Acc: 100.00%
Val Loss: 2.7348 | Val Acc: 56.25%
Precision: 0.4962 | Recall: 0.4974 | F1 Score: 0.4760
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 49: 53
Label distribution in training epoch: Counter({0: 51, 1: 42})

Validation loss did not improve. Patience: 48/50

Epoch 50/100
Train Loss: 0.0042 | Train Acc: 100.00%
Val Loss: 2.6335 | Val Acc: 51.56%
Precision: 0.4949 | Recall: 0.4949 | F1 Score: 0.4948
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 50: 58
Label distribution in training epoch: Counter({0: 53, 1: 40})

Validation loss did not improve. Patience: 49/50

Epoch 51/100
Train Loss: 0.0042 | Train Acc: 100.00%
Val Loss: 2.5119 | Val Acc: 45.31%
Precision: 0.4550 | Recall: 0.4544 | F1 Score: 0.4519
Current AMP scale: 16384.0
Unique augmented volumes seen in epoch 51: 61
Label distribution in training epoch: Counter({1: 51, 0: 42})

Validation loss did not improve. Patience: 50/50

Early stopping triggered after 51 epochs.


Training complete.
Loading best model from /home/etudiant/Projets/Viviane/LIDC-ML/models/best_model_resnet_pytorch3D_architecture_v0.pth for final metrics.
######## Training Finished in 0h 44m 30s ###########
Test Accuracy on 64 images: 71.88%
AUC: 0.7232
AUC: 0.6357
Class 0-non-cancer: Precision: 0.83, Recall: 0.62, F1-Score: 0.71
Class 1-cancer: Precision: 0.56, Recall: 0.79, F1-Score: 0.66
